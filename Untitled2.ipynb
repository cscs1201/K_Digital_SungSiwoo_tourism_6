{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Activation \n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = pd.read_csv('dataset/multiTimeline_w_n.csv')\n",
    "data1 = pd.read_excel('dataset/multiTimeline_w_n.xlsx')\n",
    "data2 = pd.read_excel('dataset/방한_외래관광객21.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            data\n",
      "date            \n",
      "2016-01-03    17\n",
      "2016-01-10    18\n",
      "2016-01-17    17\n",
      "2016-01-24    16\n",
      "2016-01-31    15\n",
      "...          ...\n",
      "2019-12-01    51\n",
      "2019-12-08    55\n",
      "2019-12-15    52\n",
      "2019-12-22    56\n",
      "2019-12-29    54\n",
      "\n",
      "[209 rows x 1 columns]\n",
      "                인원수\n",
      "년                  \n",
      "2016-01-01  1077431\n",
      "2016-02-01  1126250\n",
      "2016-03-01  1389399\n",
      "2016-04-01  1469674\n",
      "2016-05-01  1492680\n",
      "...             ...\n",
      "2020-10-01    61585\n",
      "2020-11-01    61764\n",
      "2020-12-01    62344\n",
      "2021-01-01    58397\n",
      "2021-02-01    65582\n",
      "\n",
      "[62 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# 인덱스를 등록\n",
    "\n",
    "df1 = data1.set_index('date') #이거 함수 만들까?\n",
    "\n",
    "df2 = data2.set_index('년')\n",
    "\n",
    "\n",
    "df1.index = pd.to_datetime(df1.index)\n",
    "\n",
    "df2.index = pd.to_datetime(df2.index)\n",
    "\n",
    "\n",
    "print(df1)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-1\n",
      "2016-2\n",
      "2016-3\n",
      "2016-4\n",
      "2016-5\n",
      "2016-6\n",
      "2016-7\n",
      "2016-8\n",
      "2016-9\n",
      "2016-10\n",
      "2016-11\n",
      "2016-12\n",
      "2017-1\n",
      "2017-2\n",
      "2017-3\n",
      "2017-4\n",
      "2017-5\n",
      "2017-6\n",
      "2017-7\n",
      "2017-8\n",
      "2017-9\n",
      "2017-10\n",
      "2017-11\n",
      "2017-12\n",
      "2018-1\n",
      "2018-2\n",
      "2018-3\n",
      "2018-4\n",
      "2018-5\n",
      "2018-6\n",
      "2018-7\n",
      "2018-8\n",
      "2018-9\n",
      "2018-10\n",
      "2018-11\n",
      "2018-12\n",
      "2019-1\n",
      "2019-2\n",
      "2019-3\n",
      "2019-4\n",
      "2019-5\n",
      "2019-6\n",
      "2019-7\n",
      "2019-8\n",
      "2019-9\n",
      "2019-10\n",
      "2019-11\n",
      "2019-12\n",
      "2020-1\n",
      "종료\n",
      "2021-1\n",
      "종료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[            data\n",
       " date            \n",
       " 2016-01-03    17\n",
       " 2016-01-10    18\n",
       " 2016-01-17    17\n",
       " 2016-01-24    16\n",
       " 2016-01-31    15,\n",
       "             data\n",
       " date            \n",
       " 2016-02-07    15\n",
       " 2016-02-14    20\n",
       " 2016-02-21    17\n",
       " 2016-02-28    19,\n",
       "             data\n",
       " date            \n",
       " 2016-03-06    20\n",
       " 2016-03-13    19\n",
       " 2016-03-20    19\n",
       " 2016-03-27    24,\n",
       "             data\n",
       " date            \n",
       " 2016-04-03    19\n",
       " 2016-04-10    19\n",
       " 2016-04-17    19\n",
       " 2016-04-24    18,\n",
       "             data\n",
       " date            \n",
       " 2016-05-01    17\n",
       " 2016-05-08    20\n",
       " 2016-05-15    20\n",
       " 2016-05-22    19\n",
       " 2016-05-29    20,\n",
       "             data\n",
       " date            \n",
       " 2016-06-05    19\n",
       " 2016-06-12    21\n",
       " 2016-06-19    17\n",
       " 2016-06-26    18,\n",
       "             data\n",
       " date            \n",
       " 2016-07-03    20\n",
       " 2016-07-10    21\n",
       " 2016-07-17    20\n",
       " 2016-07-24    18\n",
       " 2016-07-31    21,\n",
       "             data\n",
       " date            \n",
       " 2016-08-07    19\n",
       " 2016-08-14    16\n",
       " 2016-08-21    20\n",
       " 2016-08-28    20,\n",
       "             data\n",
       " date            \n",
       " 2016-09-04    20\n",
       " 2016-09-11    20\n",
       " 2016-09-18    20\n",
       " 2016-09-25    19,\n",
       "             data\n",
       " date            \n",
       " 2016-10-02    20\n",
       " 2016-10-09    19\n",
       " 2016-10-16    19\n",
       " 2016-10-23    19\n",
       " 2016-10-30    18,\n",
       "             data\n",
       " date            \n",
       " 2016-11-06    19\n",
       " 2016-11-13    20\n",
       " 2016-11-20    19\n",
       " 2016-11-27    22,\n",
       "             data\n",
       " date            \n",
       " 2016-12-04    41\n",
       " 2016-12-11    42\n",
       " 2016-12-18    42\n",
       " 2016-12-25    46,\n",
       "             data\n",
       " date            \n",
       " 2017-01-01    55\n",
       " 2017-01-08    53\n",
       " 2017-01-15    47\n",
       " 2017-01-22    51\n",
       " 2017-01-29    48,\n",
       "             data\n",
       " date            \n",
       " 2017-02-05    54\n",
       " 2017-02-12    50\n",
       " 2017-02-19    52\n",
       " 2017-02-26    53,\n",
       "             data\n",
       " date            \n",
       " 2017-03-05    57\n",
       " 2017-03-12    57\n",
       " 2017-03-19    57\n",
       " 2017-03-26    54,\n",
       "             data\n",
       " date            \n",
       " 2017-04-02    48\n",
       " 2017-04-09    57\n",
       " 2017-04-16    52\n",
       " 2017-04-23    47\n",
       " 2017-04-30    46,\n",
       "             data\n",
       " date            \n",
       " 2017-05-07    42\n",
       " 2017-05-14    44\n",
       " 2017-05-21    46\n",
       " 2017-05-28    44,\n",
       "             data\n",
       " date            \n",
       " 2017-06-04    42\n",
       " 2017-06-11    44\n",
       " 2017-06-18    49\n",
       " 2017-06-25    47,\n",
       "             data\n",
       " date            \n",
       " 2017-07-02    51\n",
       " 2017-07-09    50\n",
       " 2017-07-16    45\n",
       " 2017-07-23    49\n",
       " 2017-07-30    47,\n",
       "             data\n",
       " date            \n",
       " 2017-08-06    47\n",
       " 2017-08-13    51\n",
       " 2017-08-20    50\n",
       " 2017-08-27    49,\n",
       "             data\n",
       " date            \n",
       " 2017-09-03    50\n",
       " 2017-09-10    50\n",
       " 2017-09-17    49\n",
       " 2017-09-24    47,\n",
       "             data\n",
       " date            \n",
       " 2017-10-01    50\n",
       " 2017-10-08    51\n",
       " 2017-10-15    47\n",
       " 2017-10-22    47\n",
       " 2017-10-29    51,\n",
       "             data\n",
       " date            \n",
       " 2017-11-05    55\n",
       " 2017-11-12    48\n",
       " 2017-11-19    47\n",
       " 2017-11-26    45,\n",
       "             data\n",
       " date            \n",
       " 2017-12-03    46\n",
       " 2017-12-10    47\n",
       " 2017-12-17    47\n",
       " 2017-12-24    51\n",
       " 2017-12-31    54,\n",
       "             data\n",
       " date            \n",
       " 2018-01-07    53\n",
       " 2018-01-14    56\n",
       " 2018-01-21    55\n",
       " 2018-01-28    50,\n",
       "             data\n",
       " date            \n",
       " 2018-02-04    59\n",
       " 2018-02-11    56\n",
       " 2018-02-18    58\n",
       " 2018-02-25    57,\n",
       "             data\n",
       " date            \n",
       " 2018-03-04    60\n",
       " 2018-03-11    56\n",
       " 2018-03-18    58\n",
       " 2018-03-25    53,\n",
       "             data\n",
       " date            \n",
       " 2018-04-01    56\n",
       " 2018-04-08    52\n",
       " 2018-04-15    49\n",
       " 2018-04-22    53\n",
       " 2018-04-29    57,\n",
       "             data\n",
       " date            \n",
       " 2018-05-06    50\n",
       " 2018-05-13    50\n",
       " 2018-05-20    55\n",
       " 2018-05-27    56,\n",
       "             data\n",
       " date            \n",
       " 2018-06-03    57\n",
       " 2018-06-10    57\n",
       " 2018-06-17    72\n",
       " 2018-06-24    71,\n",
       "             data\n",
       " date            \n",
       " 2018-07-01    58\n",
       " 2018-07-08    58\n",
       " 2018-07-15    53\n",
       " 2018-07-22    52\n",
       " 2018-07-29    57,\n",
       "             data\n",
       " date            \n",
       " 2018-08-05    57\n",
       " 2018-08-12    60\n",
       " 2018-08-19    64\n",
       " 2018-08-26    69,\n",
       "             data\n",
       " date            \n",
       " 2018-09-02    59\n",
       " 2018-09-09    58\n",
       " 2018-09-16    53\n",
       " 2018-09-23    52\n",
       " 2018-09-30    54,\n",
       "             data\n",
       " date            \n",
       " 2018-10-07    59\n",
       " 2018-10-14    60\n",
       " 2018-10-21    55\n",
       " 2018-10-28    55,\n",
       "             data\n",
       " date            \n",
       " 2018-11-04    51\n",
       " 2018-11-11    52\n",
       " 2018-11-18    53\n",
       " 2018-11-25    51,\n",
       "             data\n",
       " date            \n",
       " 2018-12-02    49\n",
       " 2018-12-09    49\n",
       " 2018-12-16    51\n",
       " 2018-12-23    57\n",
       " 2018-12-30    61,\n",
       "             data\n",
       " date            \n",
       " 2019-01-06    60\n",
       " 2019-01-13    58\n",
       " 2019-01-20    53\n",
       " 2019-01-27    26,\n",
       "             data\n",
       " date            \n",
       " 2019-02-03    21\n",
       " 2019-02-10    20\n",
       " 2019-02-17    24\n",
       " 2019-02-24    22,\n",
       "             data\n",
       " date            \n",
       " 2019-03-03    21\n",
       " 2019-03-10    21\n",
       " 2019-03-17    22\n",
       " 2019-03-24    23\n",
       " 2019-03-31    51,\n",
       "             data\n",
       " date            \n",
       " 2019-04-07    55\n",
       " 2019-04-14    54\n",
       " 2019-04-21    62\n",
       " 2019-04-28    59,\n",
       "             data\n",
       " date            \n",
       " 2019-05-05    54\n",
       " 2019-05-12    52\n",
       " 2019-05-19    55\n",
       " 2019-05-26    56,\n",
       "             data\n",
       " date            \n",
       " 2019-06-02    57\n",
       " 2019-06-09    61\n",
       " 2019-06-16    61\n",
       " 2019-06-23    64\n",
       " 2019-06-30    63,\n",
       "             data\n",
       " date            \n",
       " 2019-07-07    64\n",
       " 2019-07-14    63\n",
       " 2019-07-21    61\n",
       " 2019-07-28    63,\n",
       "             data\n",
       " date            \n",
       " 2019-08-04    64\n",
       " 2019-08-11    64\n",
       " 2019-08-18    65\n",
       " 2019-08-25    61,\n",
       "             data\n",
       " date            \n",
       " 2019-09-01    60\n",
       " 2019-09-08    57\n",
       " 2019-09-15    56\n",
       " 2019-09-22    57\n",
       " 2019-09-29    53,\n",
       "             data\n",
       " date            \n",
       " 2019-10-06    65\n",
       " 2019-10-13    55\n",
       " 2019-10-20    55\n",
       " 2019-10-27    55,\n",
       "             data\n",
       " date            \n",
       " 2019-11-03    56\n",
       " 2019-11-10    56\n",
       " 2019-11-17    59\n",
       " 2019-11-24    53,\n",
       "             data\n",
       " date            \n",
       " 2019-12-01    51\n",
       " 2019-12-08    55\n",
       " 2019-12-15    52\n",
       " 2019-12-22    56\n",
       " 2019-12-29    54]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_1 (관심도 할당됨) 나누기\n",
    "\n",
    "def Create_Windows(y, m):\n",
    "    results = []\n",
    "\n",
    "    for y in df_date_y:\n",
    "        for m in df_date_m:\n",
    "            try:\n",
    "                target_period = str(y) +\"-\"+str(m)\n",
    "                print(target_period)\n",
    "                results.append(df1[target_period])\n",
    "            except (KeyError):\n",
    "                print(\"종료\")\n",
    "                break\n",
    "    return results\n",
    "\n",
    "df_date_y = range(2016,2022)\n",
    "df_date_m = range(1,13)\n",
    "\n",
    "df_1_tw = Create_Windows(df_date_y,df_date_m)\n",
    "df_1_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 미래의 y 값 함수\n",
    "# def y_data_call (Input_date,n):\n",
    "#     # 계산값을 담을 변수 \n",
    "#     forecast_target_month = datetime.timedelta(months=n)\n",
    "#     Calculated_time = Input_date + forecast_target_month\n",
    "#     return Calculated_time\n",
    "\n",
    "# 미래의 y 값 함수 (이름을 바꿀까? y 값 당겨오기)\n",
    "def y_data_call (n):\n",
    "    y_operation = df2[n:]\n",
    "    return y_operation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바로 저번달의 최신 데이터 날짜 가져오기\n",
    "def last_week_data_1w_call (Input_date): \n",
    "    forecast_target_week = datetime.timedelta(weeks=1)\n",
    "    Calculated_time = Input_date - forecast_target_week\n",
    "    return Calculated_time\n",
    "\n",
    "#여기선 상속을 쓰던가? 일단 빨리 구현하자..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Transpose_scalar_DataFrame_transform (test1):\n",
    "    test2 = pd.DataFrame(test1)\n",
    "    test2 = test2.T # 이 방식으로 만들자\n",
    "    test2 # 뭐... 누가봐도 대충이긴 한대... 이젠 귀찮아...\n",
    "    #아! 리턴을 안햇내 하하...\n",
    "    return test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            data\n",
       " date            \n",
       " 2016-01-03    17\n",
       " 2016-01-10    18\n",
       " 2016-01-17    17\n",
       " 2016-01-24    16\n",
       " 2016-01-31    15,\n",
       "             data\n",
       " 2016-01-31    15\n",
       " 2016-02-07    15\n",
       " 2016-02-14    20\n",
       " 2016-02-21    17\n",
       " 2016-02-28    19,\n",
       "             data\n",
       " 2016-02-28    19\n",
       " 2016-03-06    20\n",
       " 2016-03-13    19\n",
       " 2016-03-20    19\n",
       " 2016-03-27    24,\n",
       "             data\n",
       " 2016-03-27    24\n",
       " 2016-04-03    19\n",
       " 2016-04-10    19\n",
       " 2016-04-17    19\n",
       " 2016-04-24    18,\n",
       "             data\n",
       " date            \n",
       " 2016-05-01    17\n",
       " 2016-05-08    20\n",
       " 2016-05-15    20\n",
       " 2016-05-22    19\n",
       " 2016-05-29    20,\n",
       "             data\n",
       " 2016-05-29    20\n",
       " 2016-06-05    19\n",
       " 2016-06-12    21\n",
       " 2016-06-19    17\n",
       " 2016-06-26    18,\n",
       "             data\n",
       " date            \n",
       " 2016-07-03    20\n",
       " 2016-07-10    21\n",
       " 2016-07-17    20\n",
       " 2016-07-24    18\n",
       " 2016-07-31    21,\n",
       "             data\n",
       " 2016-07-31    21\n",
       " 2016-08-07    19\n",
       " 2016-08-14    16\n",
       " 2016-08-21    20\n",
       " 2016-08-28    20,\n",
       "             data\n",
       " 2016-08-28    20\n",
       " 2016-09-04    20\n",
       " 2016-09-11    20\n",
       " 2016-09-18    20\n",
       " 2016-09-25    19,\n",
       "             data\n",
       " date            \n",
       " 2016-10-02    20\n",
       " 2016-10-09    19\n",
       " 2016-10-16    19\n",
       " 2016-10-23    19\n",
       " 2016-10-30    18,\n",
       "             data\n",
       " 2016-10-30    18\n",
       " 2016-11-06    19\n",
       " 2016-11-13    20\n",
       " 2016-11-20    19\n",
       " 2016-11-27    22,\n",
       "             data\n",
       " 2016-11-27    22\n",
       " 2016-12-04    41\n",
       " 2016-12-11    42\n",
       " 2016-12-18    42\n",
       " 2016-12-25    46,\n",
       "             data\n",
       " date            \n",
       " 2017-01-01    55\n",
       " 2017-01-08    53\n",
       " 2017-01-15    47\n",
       " 2017-01-22    51\n",
       " 2017-01-29    48,\n",
       "             data\n",
       " 2017-01-29    48\n",
       " 2017-02-05    54\n",
       " 2017-02-12    50\n",
       " 2017-02-19    52\n",
       " 2017-02-26    53,\n",
       "             data\n",
       " 2017-02-26    53\n",
       " 2017-03-05    57\n",
       " 2017-03-12    57\n",
       " 2017-03-19    57\n",
       " 2017-03-26    54,\n",
       "             data\n",
       " date            \n",
       " 2017-04-02    48\n",
       " 2017-04-09    57\n",
       " 2017-04-16    52\n",
       " 2017-04-23    47\n",
       " 2017-04-30    46,\n",
       "             data\n",
       " 2017-04-30    46\n",
       " 2017-05-07    42\n",
       " 2017-05-14    44\n",
       " 2017-05-21    46\n",
       " 2017-05-28    44,\n",
       "             data\n",
       " 2017-05-28    44\n",
       " 2017-06-04    42\n",
       " 2017-06-11    44\n",
       " 2017-06-18    49\n",
       " 2017-06-25    47,\n",
       "             data\n",
       " date            \n",
       " 2017-07-02    51\n",
       " 2017-07-09    50\n",
       " 2017-07-16    45\n",
       " 2017-07-23    49\n",
       " 2017-07-30    47,\n",
       "             data\n",
       " 2017-07-30    47\n",
       " 2017-08-06    47\n",
       " 2017-08-13    51\n",
       " 2017-08-20    50\n",
       " 2017-08-27    49,\n",
       "             data\n",
       " 2017-08-27    49\n",
       " 2017-09-03    50\n",
       " 2017-09-10    50\n",
       " 2017-09-17    49\n",
       " 2017-09-24    47,\n",
       "             data\n",
       " date            \n",
       " 2017-10-01    50\n",
       " 2017-10-08    51\n",
       " 2017-10-15    47\n",
       " 2017-10-22    47\n",
       " 2017-10-29    51,\n",
       "             data\n",
       " 2017-10-29    51\n",
       " 2017-11-05    55\n",
       " 2017-11-12    48\n",
       " 2017-11-19    47\n",
       " 2017-11-26    45,\n",
       "             data\n",
       " date            \n",
       " 2017-12-03    46\n",
       " 2017-12-10    47\n",
       " 2017-12-17    47\n",
       " 2017-12-24    51\n",
       " 2017-12-31    54,\n",
       "             data\n",
       " 2017-12-31    54\n",
       " 2018-01-07    53\n",
       " 2018-01-14    56\n",
       " 2018-01-21    55\n",
       " 2018-01-28    50,\n",
       "             data\n",
       " 2018-01-28    50\n",
       " 2018-02-04    59\n",
       " 2018-02-11    56\n",
       " 2018-02-18    58\n",
       " 2018-02-25    57,\n",
       "             data\n",
       " 2018-02-25    57\n",
       " 2018-03-04    60\n",
       " 2018-03-11    56\n",
       " 2018-03-18    58\n",
       " 2018-03-25    53,\n",
       "             data\n",
       " date            \n",
       " 2018-04-01    56\n",
       " 2018-04-08    52\n",
       " 2018-04-15    49\n",
       " 2018-04-22    53\n",
       " 2018-04-29    57,\n",
       "             data\n",
       " 2018-04-29    57\n",
       " 2018-05-06    50\n",
       " 2018-05-13    50\n",
       " 2018-05-20    55\n",
       " 2018-05-27    56,\n",
       "             data\n",
       " 2018-05-27    56\n",
       " 2018-06-03    57\n",
       " 2018-06-10    57\n",
       " 2018-06-17    72\n",
       " 2018-06-24    71,\n",
       "             data\n",
       " date            \n",
       " 2018-07-01    58\n",
       " 2018-07-08    58\n",
       " 2018-07-15    53\n",
       " 2018-07-22    52\n",
       " 2018-07-29    57,\n",
       "             data\n",
       " 2018-07-29    57\n",
       " 2018-08-05    57\n",
       " 2018-08-12    60\n",
       " 2018-08-19    64\n",
       " 2018-08-26    69,\n",
       "             data\n",
       " date            \n",
       " 2018-09-02    59\n",
       " 2018-09-09    58\n",
       " 2018-09-16    53\n",
       " 2018-09-23    52\n",
       " 2018-09-30    54,\n",
       "             data\n",
       " 2018-09-30    54\n",
       " 2018-10-07    59\n",
       " 2018-10-14    60\n",
       " 2018-10-21    55\n",
       " 2018-10-28    55,\n",
       "             data\n",
       " 2018-10-28    55\n",
       " 2018-11-04    51\n",
       " 2018-11-11    52\n",
       " 2018-11-18    53\n",
       " 2018-11-25    51,\n",
       "             data\n",
       " date            \n",
       " 2018-12-02    49\n",
       " 2018-12-09    49\n",
       " 2018-12-16    51\n",
       " 2018-12-23    57\n",
       " 2018-12-30    61,\n",
       "             data\n",
       " 2018-12-30    61\n",
       " 2019-01-06    60\n",
       " 2019-01-13    58\n",
       " 2019-01-20    53\n",
       " 2019-01-27    26,\n",
       "             data\n",
       " 2019-01-27    26\n",
       " 2019-02-03    21\n",
       " 2019-02-10    20\n",
       " 2019-02-17    24\n",
       " 2019-02-24    22,\n",
       "             data\n",
       " date            \n",
       " 2019-03-03    21\n",
       " 2019-03-10    21\n",
       " 2019-03-17    22\n",
       " 2019-03-24    23\n",
       " 2019-03-31    51,\n",
       "             data\n",
       " 2019-03-31    51\n",
       " 2019-04-07    55\n",
       " 2019-04-14    54\n",
       " 2019-04-21    62\n",
       " 2019-04-28    59,\n",
       "             data\n",
       " 2019-04-28    59\n",
       " 2019-05-05    54\n",
       " 2019-05-12    52\n",
       " 2019-05-19    55\n",
       " 2019-05-26    56,\n",
       "             data\n",
       " date            \n",
       " 2019-06-02    57\n",
       " 2019-06-09    61\n",
       " 2019-06-16    61\n",
       " 2019-06-23    64\n",
       " 2019-06-30    63,\n",
       "             data\n",
       " 2019-06-30    63\n",
       " 2019-07-07    64\n",
       " 2019-07-14    63\n",
       " 2019-07-21    61\n",
       " 2019-07-28    63,\n",
       "             data\n",
       " 2019-07-28    63\n",
       " 2019-08-04    64\n",
       " 2019-08-11    64\n",
       " 2019-08-18    65\n",
       " 2019-08-25    61,\n",
       "             data\n",
       " date            \n",
       " 2019-09-01    60\n",
       " 2019-09-08    57\n",
       " 2019-09-15    56\n",
       " 2019-09-22    57\n",
       " 2019-09-29    53,\n",
       "             data\n",
       " 2019-09-29    53\n",
       " 2019-10-06    65\n",
       " 2019-10-13    55\n",
       " 2019-10-20    55\n",
       " 2019-10-27    55,\n",
       "             data\n",
       " 2019-10-27    55\n",
       " 2019-11-03    56\n",
       " 2019-11-10    56\n",
       " 2019-11-17    59\n",
       " 2019-11-24    53,\n",
       "             data\n",
       " date            \n",
       " 2019-12-01    51\n",
       " 2019-12-08    55\n",
       " 2019-12-15    52\n",
       " 2019-12-22    56\n",
       " 2019-12-29    54]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_1_tw 의 길이 4인 행만 골라서 그 이전달의 최신 데이터 가져오기\n",
    "\n",
    "df_1_w = []\n",
    "for Tew_v in df_1_tw:\n",
    "    \n",
    "#     df_1_w_in = Tew_v\n",
    "    if len(Tew_v) < 5:\n",
    "        \n",
    "        a = last_week_data_1w_call(Tew_v.index[0])\n",
    "        week_ago_data = df1.loc[a]\n",
    "#         b = pd.DataFrame(week_ago_data)\n",
    "        b = Transpose_scalar_DataFrame_transform(week_ago_data) # 데이터 프레임 변환 -> 전치시킴\n",
    "#         print(b) #아!\n",
    "        df_1_w_in = pd.concat([b, Tew_v])\n",
    "        df_1_w.append(df_1_w_in)\n",
    "    else:\n",
    "        df_1_w.append(Tew_v)\n",
    "\n",
    "df_1_w #  성공....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-01-03 00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_tw[0].index[0] #(이걸 집어 넣기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data    17\n",
       "Name: 2016-01-03 00:00:00, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df1.index['2016-01-03 00:00:00'] #예상 못한 상황\n",
    "df1.loc['2016-01-03 00:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>인원수</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>년</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>1126250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>1389399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>1469674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-01</th>\n",
       "      <td>1492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01</th>\n",
       "      <td>1554413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>61585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>61764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>62344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>58397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01</th>\n",
       "      <td>65582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                인원수\n",
       "년                  \n",
       "2016-02-01  1126250\n",
       "2016-03-01  1389399\n",
       "2016-04-01  1469674\n",
       "2016-05-01  1492680\n",
       "2016-06-01  1554413\n",
       "...             ...\n",
       "2020-10-01    61585\n",
       "2020-11-01    61764\n",
       "2020-12-01    62344\n",
       "2021-01-01    58397\n",
       "2021-02-01    65582\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>인원수</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>년</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-02-01</th>\n",
       "      <td>1126250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>1389399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-01</th>\n",
       "      <td>1469674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-01</th>\n",
       "      <td>1492680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-01</th>\n",
       "      <td>1554413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>61585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>61764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>62344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01</th>\n",
       "      <td>58397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-01</th>\n",
       "      <td>65582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                인원수\n",
       "년                  \n",
       "2016-02-01  1126250\n",
       "2016-03-01  1389399\n",
       "2016-04-01  1469674\n",
       "2016-05-01  1492680\n",
       "2016-06-01  1554413\n",
       "...             ...\n",
       "2020-10-01    61585\n",
       "2020-11-01    61764\n",
       "2020-12-01    62344\n",
       "2021-01-01    58397\n",
       "2021-02-01    65582\n",
       "\n",
       "[61 rows x 1 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2_w = y_data_call(1)# [1개만 앞으로 당김]\n",
    "df_2_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            data\n",
       " date            \n",
       " 2016-01-03    17\n",
       " 2016-01-10    18\n",
       " 2016-01-17    17\n",
       " 2016-01-24    16\n",
       " 2016-01-31    15,\n",
       "             data\n",
       " 2016-01-31    15\n",
       " 2016-02-07    15\n",
       " 2016-02-14    20\n",
       " 2016-02-21    17\n",
       " 2016-02-28    19,\n",
       "             data\n",
       " 2016-02-28    19\n",
       " 2016-03-06    20\n",
       " 2016-03-13    19\n",
       " 2016-03-20    19\n",
       " 2016-03-27    24,\n",
       "             data\n",
       " 2016-03-27    24\n",
       " 2016-04-03    19\n",
       " 2016-04-10    19\n",
       " 2016-04-17    19\n",
       " 2016-04-24    18,\n",
       "             data\n",
       " date            \n",
       " 2016-05-01    17\n",
       " 2016-05-08    20\n",
       " 2016-05-15    20\n",
       " 2016-05-22    19\n",
       " 2016-05-29    20,\n",
       "             data\n",
       " 2016-05-29    20\n",
       " 2016-06-05    19\n",
       " 2016-06-12    21\n",
       " 2016-06-19    17\n",
       " 2016-06-26    18,\n",
       "             data\n",
       " date            \n",
       " 2016-07-03    20\n",
       " 2016-07-10    21\n",
       " 2016-07-17    20\n",
       " 2016-07-24    18\n",
       " 2016-07-31    21,\n",
       "             data\n",
       " 2016-07-31    21\n",
       " 2016-08-07    19\n",
       " 2016-08-14    16\n",
       " 2016-08-21    20\n",
       " 2016-08-28    20,\n",
       "             data\n",
       " 2016-08-28    20\n",
       " 2016-09-04    20\n",
       " 2016-09-11    20\n",
       " 2016-09-18    20\n",
       " 2016-09-25    19,\n",
       "             data\n",
       " date            \n",
       " 2016-10-02    20\n",
       " 2016-10-09    19\n",
       " 2016-10-16    19\n",
       " 2016-10-23    19\n",
       " 2016-10-30    18,\n",
       "             data\n",
       " 2016-10-30    18\n",
       " 2016-11-06    19\n",
       " 2016-11-13    20\n",
       " 2016-11-20    19\n",
       " 2016-11-27    22,\n",
       "             data\n",
       " 2016-11-27    22\n",
       " 2016-12-04    41\n",
       " 2016-12-11    42\n",
       " 2016-12-18    42\n",
       " 2016-12-25    46,\n",
       "             data\n",
       " date            \n",
       " 2017-01-01    55\n",
       " 2017-01-08    53\n",
       " 2017-01-15    47\n",
       " 2017-01-22    51\n",
       " 2017-01-29    48,\n",
       "             data\n",
       " 2017-01-29    48\n",
       " 2017-02-05    54\n",
       " 2017-02-12    50\n",
       " 2017-02-19    52\n",
       " 2017-02-26    53,\n",
       "             data\n",
       " 2017-02-26    53\n",
       " 2017-03-05    57\n",
       " 2017-03-12    57\n",
       " 2017-03-19    57\n",
       " 2017-03-26    54,\n",
       "             data\n",
       " date            \n",
       " 2017-04-02    48\n",
       " 2017-04-09    57\n",
       " 2017-04-16    52\n",
       " 2017-04-23    47\n",
       " 2017-04-30    46,\n",
       "             data\n",
       " 2017-04-30    46\n",
       " 2017-05-07    42\n",
       " 2017-05-14    44\n",
       " 2017-05-21    46\n",
       " 2017-05-28    44,\n",
       "             data\n",
       " 2017-05-28    44\n",
       " 2017-06-04    42\n",
       " 2017-06-11    44\n",
       " 2017-06-18    49\n",
       " 2017-06-25    47,\n",
       "             data\n",
       " date            \n",
       " 2017-07-02    51\n",
       " 2017-07-09    50\n",
       " 2017-07-16    45\n",
       " 2017-07-23    49\n",
       " 2017-07-30    47,\n",
       "             data\n",
       " 2017-07-30    47\n",
       " 2017-08-06    47\n",
       " 2017-08-13    51\n",
       " 2017-08-20    50\n",
       " 2017-08-27    49,\n",
       "             data\n",
       " 2017-08-27    49\n",
       " 2017-09-03    50\n",
       " 2017-09-10    50\n",
       " 2017-09-17    49\n",
       " 2017-09-24    47,\n",
       "             data\n",
       " date            \n",
       " 2017-10-01    50\n",
       " 2017-10-08    51\n",
       " 2017-10-15    47\n",
       " 2017-10-22    47\n",
       " 2017-10-29    51,\n",
       "             data\n",
       " 2017-10-29    51\n",
       " 2017-11-05    55\n",
       " 2017-11-12    48\n",
       " 2017-11-19    47\n",
       " 2017-11-26    45,\n",
       "             data\n",
       " date            \n",
       " 2017-12-03    46\n",
       " 2017-12-10    47\n",
       " 2017-12-17    47\n",
       " 2017-12-24    51\n",
       " 2017-12-31    54,\n",
       "             data\n",
       " 2017-12-31    54\n",
       " 2018-01-07    53\n",
       " 2018-01-14    56\n",
       " 2018-01-21    55\n",
       " 2018-01-28    50,\n",
       "             data\n",
       " 2018-01-28    50\n",
       " 2018-02-04    59\n",
       " 2018-02-11    56\n",
       " 2018-02-18    58\n",
       " 2018-02-25    57,\n",
       "             data\n",
       " 2018-02-25    57\n",
       " 2018-03-04    60\n",
       " 2018-03-11    56\n",
       " 2018-03-18    58\n",
       " 2018-03-25    53,\n",
       "             data\n",
       " date            \n",
       " 2018-04-01    56\n",
       " 2018-04-08    52\n",
       " 2018-04-15    49\n",
       " 2018-04-22    53\n",
       " 2018-04-29    57,\n",
       "             data\n",
       " 2018-04-29    57\n",
       " 2018-05-06    50\n",
       " 2018-05-13    50\n",
       " 2018-05-20    55\n",
       " 2018-05-27    56,\n",
       "             data\n",
       " 2018-05-27    56\n",
       " 2018-06-03    57\n",
       " 2018-06-10    57\n",
       " 2018-06-17    72\n",
       " 2018-06-24    71,\n",
       "             data\n",
       " date            \n",
       " 2018-07-01    58\n",
       " 2018-07-08    58\n",
       " 2018-07-15    53\n",
       " 2018-07-22    52\n",
       " 2018-07-29    57,\n",
       "             data\n",
       " 2018-07-29    57\n",
       " 2018-08-05    57\n",
       " 2018-08-12    60\n",
       " 2018-08-19    64\n",
       " 2018-08-26    69,\n",
       "             data\n",
       " date            \n",
       " 2018-09-02    59\n",
       " 2018-09-09    58\n",
       " 2018-09-16    53\n",
       " 2018-09-23    52\n",
       " 2018-09-30    54,\n",
       "             data\n",
       " 2018-09-30    54\n",
       " 2018-10-07    59\n",
       " 2018-10-14    60\n",
       " 2018-10-21    55\n",
       " 2018-10-28    55,\n",
       "             data\n",
       " 2018-10-28    55\n",
       " 2018-11-04    51\n",
       " 2018-11-11    52\n",
       " 2018-11-18    53\n",
       " 2018-11-25    51,\n",
       "             data\n",
       " date            \n",
       " 2018-12-02    49\n",
       " 2018-12-09    49\n",
       " 2018-12-16    51\n",
       " 2018-12-23    57\n",
       " 2018-12-30    61,\n",
       "             data\n",
       " 2018-12-30    61\n",
       " 2019-01-06    60\n",
       " 2019-01-13    58\n",
       " 2019-01-20    53\n",
       " 2019-01-27    26,\n",
       "             data\n",
       " 2019-01-27    26\n",
       " 2019-02-03    21\n",
       " 2019-02-10    20\n",
       " 2019-02-17    24\n",
       " 2019-02-24    22,\n",
       "             data\n",
       " date            \n",
       " 2019-03-03    21\n",
       " 2019-03-10    21\n",
       " 2019-03-17    22\n",
       " 2019-03-24    23\n",
       " 2019-03-31    51,\n",
       "             data\n",
       " 2019-03-31    51\n",
       " 2019-04-07    55\n",
       " 2019-04-14    54\n",
       " 2019-04-21    62\n",
       " 2019-04-28    59,\n",
       "             data\n",
       " 2019-04-28    59\n",
       " 2019-05-05    54\n",
       " 2019-05-12    52\n",
       " 2019-05-19    55\n",
       " 2019-05-26    56,\n",
       "             data\n",
       " date            \n",
       " 2019-06-02    57\n",
       " 2019-06-09    61\n",
       " 2019-06-16    61\n",
       " 2019-06-23    64\n",
       " 2019-06-30    63,\n",
       "             data\n",
       " 2019-06-30    63\n",
       " 2019-07-07    64\n",
       " 2019-07-14    63\n",
       " 2019-07-21    61\n",
       " 2019-07-28    63,\n",
       "             data\n",
       " 2019-07-28    63\n",
       " 2019-08-04    64\n",
       " 2019-08-11    64\n",
       " 2019-08-18    65\n",
       " 2019-08-25    61,\n",
       "             data\n",
       " date            \n",
       " 2019-09-01    60\n",
       " 2019-09-08    57\n",
       " 2019-09-15    56\n",
       " 2019-09-22    57\n",
       " 2019-09-29    53,\n",
       "             data\n",
       " 2019-09-29    53\n",
       " 2019-10-06    65\n",
       " 2019-10-13    55\n",
       " 2019-10-20    55\n",
       " 2019-10-27    55,\n",
       "             data\n",
       " 2019-10-27    55\n",
       " 2019-11-03    56\n",
       " 2019-11-10    56\n",
       " 2019-11-17    59\n",
       " 2019-11-24    53,\n",
       "             data\n",
       " date            \n",
       " 2019-12-01    51\n",
       " 2019-12-08    55\n",
       " 2019-12-15    52\n",
       " 2019-12-22    56\n",
       " 2019-12-29    54]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_n = 62\n",
    "c = 1\n",
    "df1_nc = df_1_w[:df1_n-c]\n",
    "df1_nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#지금 아무래도 2개의 데이터 프레임이 정상적으로 섞일것 같지가 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 5, 50)             10400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 39,905\n",
      "Trainable params: 39,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#슬슬 도전해 볼까?\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(5,1)))\n",
    "model.add(LSTM(64, return_sequences=False)) #return_sequences 가 뭐지?\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예상 시나리오중 하나.... 순서대로 해서 9:!로 나누면 뭘 해도 loss가 줄어들지 않을것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[            data\n",
       " date            \n",
       " 2016-01-03    17\n",
       " 2016-01-10    18\n",
       " 2016-01-17    17\n",
       " 2016-01-24    16\n",
       " 2016-01-31    15,\n",
       "             data\n",
       " 2016-01-31    15\n",
       " 2016-02-07    15\n",
       " 2016-02-14    20\n",
       " 2016-02-21    17\n",
       " 2016-02-28    19,\n",
       "             data\n",
       " 2016-02-28    19\n",
       " 2016-03-06    20\n",
       " 2016-03-13    19\n",
       " 2016-03-20    19\n",
       " 2016-03-27    24,\n",
       "             data\n",
       " 2016-03-27    24\n",
       " 2016-04-03    19\n",
       " 2016-04-10    19\n",
       " 2016-04-17    19\n",
       " 2016-04-24    18,\n",
       "             data\n",
       " date            \n",
       " 2016-05-01    17\n",
       " 2016-05-08    20\n",
       " 2016-05-15    20\n",
       " 2016-05-22    19\n",
       " 2016-05-29    20,\n",
       "             data\n",
       " 2016-05-29    20\n",
       " 2016-06-05    19\n",
       " 2016-06-12    21\n",
       " 2016-06-19    17\n",
       " 2016-06-26    18,\n",
       "             data\n",
       " date            \n",
       " 2016-07-03    20\n",
       " 2016-07-10    21\n",
       " 2016-07-17    20\n",
       " 2016-07-24    18\n",
       " 2016-07-31    21,\n",
       "             data\n",
       " 2016-07-31    21\n",
       " 2016-08-07    19\n",
       " 2016-08-14    16\n",
       " 2016-08-21    20\n",
       " 2016-08-28    20,\n",
       "             data\n",
       " 2016-08-28    20\n",
       " 2016-09-04    20\n",
       " 2016-09-11    20\n",
       " 2016-09-18    20\n",
       " 2016-09-25    19,\n",
       "             data\n",
       " date            \n",
       " 2016-10-02    20\n",
       " 2016-10-09    19\n",
       " 2016-10-16    19\n",
       " 2016-10-23    19\n",
       " 2016-10-30    18,\n",
       "             data\n",
       " 2016-10-30    18\n",
       " 2016-11-06    19\n",
       " 2016-11-13    20\n",
       " 2016-11-20    19\n",
       " 2016-11-27    22,\n",
       "             data\n",
       " 2016-11-27    22\n",
       " 2016-12-04    41\n",
       " 2016-12-11    42\n",
       " 2016-12-18    42\n",
       " 2016-12-25    46,\n",
       "             data\n",
       " date            \n",
       " 2017-01-01    55\n",
       " 2017-01-08    53\n",
       " 2017-01-15    47\n",
       " 2017-01-22    51\n",
       " 2017-01-29    48,\n",
       "             data\n",
       " 2017-01-29    48\n",
       " 2017-02-05    54\n",
       " 2017-02-12    50\n",
       " 2017-02-19    52\n",
       " 2017-02-26    53,\n",
       "             data\n",
       " 2017-02-26    53\n",
       " 2017-03-05    57\n",
       " 2017-03-12    57\n",
       " 2017-03-19    57\n",
       " 2017-03-26    54,\n",
       "             data\n",
       " date            \n",
       " 2017-04-02    48\n",
       " 2017-04-09    57\n",
       " 2017-04-16    52\n",
       " 2017-04-23    47\n",
       " 2017-04-30    46,\n",
       "             data\n",
       " 2017-04-30    46\n",
       " 2017-05-07    42\n",
       " 2017-05-14    44\n",
       " 2017-05-21    46\n",
       " 2017-05-28    44,\n",
       "             data\n",
       " 2017-05-28    44\n",
       " 2017-06-04    42\n",
       " 2017-06-11    44\n",
       " 2017-06-18    49\n",
       " 2017-06-25    47,\n",
       "             data\n",
       " date            \n",
       " 2017-07-02    51\n",
       " 2017-07-09    50\n",
       " 2017-07-16    45\n",
       " 2017-07-23    49\n",
       " 2017-07-30    47,\n",
       "             data\n",
       " 2017-07-30    47\n",
       " 2017-08-06    47\n",
       " 2017-08-13    51\n",
       " 2017-08-20    50\n",
       " 2017-08-27    49,\n",
       "             data\n",
       " 2017-08-27    49\n",
       " 2017-09-03    50\n",
       " 2017-09-10    50\n",
       " 2017-09-17    49\n",
       " 2017-09-24    47,\n",
       "             data\n",
       " date            \n",
       " 2017-10-01    50\n",
       " 2017-10-08    51\n",
       " 2017-10-15    47\n",
       " 2017-10-22    47\n",
       " 2017-10-29    51,\n",
       "             data\n",
       " 2017-10-29    51\n",
       " 2017-11-05    55\n",
       " 2017-11-12    48\n",
       " 2017-11-19    47\n",
       " 2017-11-26    45,\n",
       "             data\n",
       " date            \n",
       " 2017-12-03    46\n",
       " 2017-12-10    47\n",
       " 2017-12-17    47\n",
       " 2017-12-24    51\n",
       " 2017-12-31    54,\n",
       "             data\n",
       " 2017-12-31    54\n",
       " 2018-01-07    53\n",
       " 2018-01-14    56\n",
       " 2018-01-21    55\n",
       " 2018-01-28    50,\n",
       "             data\n",
       " 2018-01-28    50\n",
       " 2018-02-04    59\n",
       " 2018-02-11    56\n",
       " 2018-02-18    58\n",
       " 2018-02-25    57,\n",
       "             data\n",
       " 2018-02-25    57\n",
       " 2018-03-04    60\n",
       " 2018-03-11    56\n",
       " 2018-03-18    58\n",
       " 2018-03-25    53,\n",
       "             data\n",
       " date            \n",
       " 2018-04-01    56\n",
       " 2018-04-08    52\n",
       " 2018-04-15    49\n",
       " 2018-04-22    53\n",
       " 2018-04-29    57,\n",
       "             data\n",
       " 2018-04-29    57\n",
       " 2018-05-06    50\n",
       " 2018-05-13    50\n",
       " 2018-05-20    55\n",
       " 2018-05-27    56,\n",
       "             data\n",
       " 2018-05-27    56\n",
       " 2018-06-03    57\n",
       " 2018-06-10    57\n",
       " 2018-06-17    72\n",
       " 2018-06-24    71,\n",
       "             data\n",
       " date            \n",
       " 2018-07-01    58\n",
       " 2018-07-08    58\n",
       " 2018-07-15    53\n",
       " 2018-07-22    52\n",
       " 2018-07-29    57,\n",
       "             data\n",
       " 2018-07-29    57\n",
       " 2018-08-05    57\n",
       " 2018-08-12    60\n",
       " 2018-08-19    64\n",
       " 2018-08-26    69,\n",
       "             data\n",
       " date            \n",
       " 2018-09-02    59\n",
       " 2018-09-09    58\n",
       " 2018-09-16    53\n",
       " 2018-09-23    52\n",
       " 2018-09-30    54,\n",
       "             data\n",
       " 2018-09-30    54\n",
       " 2018-10-07    59\n",
       " 2018-10-14    60\n",
       " 2018-10-21    55\n",
       " 2018-10-28    55,\n",
       "             data\n",
       " 2018-10-28    55\n",
       " 2018-11-04    51\n",
       " 2018-11-11    52\n",
       " 2018-11-18    53\n",
       " 2018-11-25    51,\n",
       "             data\n",
       " date            \n",
       " 2018-12-02    49\n",
       " 2018-12-09    49\n",
       " 2018-12-16    51\n",
       " 2018-12-23    57\n",
       " 2018-12-30    61,\n",
       "             data\n",
       " 2018-12-30    61\n",
       " 2019-01-06    60\n",
       " 2019-01-13    58\n",
       " 2019-01-20    53\n",
       " 2019-01-27    26,\n",
       "             data\n",
       " 2019-01-27    26\n",
       " 2019-02-03    21\n",
       " 2019-02-10    20\n",
       " 2019-02-17    24\n",
       " 2019-02-24    22,\n",
       "             data\n",
       " date            \n",
       " 2019-03-03    21\n",
       " 2019-03-10    21\n",
       " 2019-03-17    22\n",
       " 2019-03-24    23\n",
       " 2019-03-31    51,\n",
       "             data\n",
       " 2019-03-31    51\n",
       " 2019-04-07    55\n",
       " 2019-04-14    54\n",
       " 2019-04-21    62\n",
       " 2019-04-28    59,\n",
       "             data\n",
       " 2019-04-28    59\n",
       " 2019-05-05    54\n",
       " 2019-05-12    52\n",
       " 2019-05-19    55\n",
       " 2019-05-26    56,\n",
       "             data\n",
       " date            \n",
       " 2019-06-02    57\n",
       " 2019-06-09    61\n",
       " 2019-06-16    61\n",
       " 2019-06-23    64\n",
       " 2019-06-30    63,\n",
       "             data\n",
       " 2019-06-30    63\n",
       " 2019-07-07    64\n",
       " 2019-07-14    63\n",
       " 2019-07-21    61\n",
       " 2019-07-28    63,\n",
       "             data\n",
       " 2019-07-28    63\n",
       " 2019-08-04    64\n",
       " 2019-08-11    64\n",
       " 2019-08-18    65\n",
       " 2019-08-25    61,\n",
       "             data\n",
       " date            \n",
       " 2019-09-01    60\n",
       " 2019-09-08    57\n",
       " 2019-09-15    56\n",
       " 2019-09-22    57\n",
       " 2019-09-29    53,\n",
       "             data\n",
       " 2019-09-29    53\n",
       " 2019-10-06    65\n",
       " 2019-10-13    55\n",
       " 2019-10-20    55\n",
       " 2019-10-27    55,\n",
       "             data\n",
       " 2019-10-27    55\n",
       " 2019-11-03    56\n",
       " 2019-11-10    56\n",
       " 2019-11-17    59\n",
       " 2019-11-24    53,\n",
       "             data\n",
       " date            \n",
       " 2019-12-01    51\n",
       " 2019-12-08    55\n",
       " 2019-12-15    52\n",
       " 2019-12-22    56\n",
       " 2019-12-29    54]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-bb335b5534a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model.fit(df_1_w[:df1_n-c], df2[1:],\n\u001b[1;32m----> 2\u001b[1;33m          \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m          epochs=20)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(df_1_w[:df1_n-c], df2[1:],\n",
    "         validation_data=(x_test, y_test),\n",
    "         batch_size=10,\n",
    "         epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = np.array(range(1,101))\n",
    "row = int(round(test3.shape[0]*0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아! 그래 2 행으로 넣자. 어차피 3차원 데이터 이니까...(-,5)\n",
    "# [[[]]]\n",
    "\n",
    "# [~~~~]\n",
    "\n",
    "# [[~~~~],\n",
    "# [~~~~]]\n",
    "\n",
    "# [[[~~~~]\n",
    "# [~~~~]]\n",
    "# [[~~~~]\n",
    "# [~~~~]]]  # 1,2,3, 차원.\n",
    "\n",
    "# test4 = np.array([[[]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[            data\n",
      "date            \n",
      "2018-07-01    58\n",
      "2018-07-08    58\n",
      "2018-07-15    53\n",
      "2018-07-22    52\n",
      "2018-07-29    57,             data\n",
      "date            \n",
      "2018-12-02    49\n",
      "2018-12-09    49\n",
      "2018-12-16    51\n",
      "2018-12-23    57\n",
      "2018-12-30    61,             data\n",
      "2018-12-30    61\n",
      "2019-01-06    60\n",
      "2019-01-13    58\n",
      "2019-01-20    53\n",
      "2019-01-27    26,             data\n",
      "date            \n",
      "2019-09-01    60\n",
      "2019-09-08    57\n",
      "2019-09-15    56\n",
      "2019-09-22    57\n",
      "2019-09-29    53,             data\n",
      "2017-05-28    44\n",
      "2017-06-04    42\n",
      "2017-06-11    44\n",
      "2017-06-18    49\n",
      "2017-06-25    47,             data\n",
      "2017-10-29    51\n",
      "2017-11-05    55\n",
      "2017-11-12    48\n",
      "2017-11-19    47\n",
      "2017-11-26    45,             data\n",
      "2016-05-29    20\n",
      "2016-06-05    19\n",
      "2016-06-12    21\n",
      "2016-06-19    17\n",
      "2016-06-26    18,             data\n",
      "date            \n",
      "2017-04-02    48\n",
      "2017-04-09    57\n",
      "2017-04-16    52\n",
      "2017-04-23    47\n",
      "2017-04-30    46,             data\n",
      "date            \n",
      "2017-12-03    46\n",
      "2017-12-10    47\n",
      "2017-12-17    47\n",
      "2017-12-24    51\n",
      "2017-12-31    54,             data\n",
      "2017-02-26    53\n",
      "2017-03-05    57\n",
      "2017-03-12    57\n",
      "2017-03-19    57\n",
      "2017-03-26    54,             data\n",
      "date            \n",
      "2016-05-01    17\n",
      "2016-05-08    20\n",
      "2016-05-15    20\n",
      "2016-05-22    19\n",
      "2016-05-29    20,             data\n",
      "2019-10-27    55\n",
      "2019-11-03    56\n",
      "2019-11-10    56\n",
      "2019-11-17    59\n",
      "2019-11-24    53,             data\n",
      "date            \n",
      "2018-09-02    59\n",
      "2018-09-09    58\n",
      "2018-09-16    53\n",
      "2018-09-23    52\n",
      "2018-09-30    54,             data\n",
      "2018-07-29    57\n",
      "2018-08-05    57\n",
      "2018-08-12    60\n",
      "2018-08-19    64\n",
      "2018-08-26    69,             data\n",
      "2019-09-29    53\n",
      "2019-10-06    65\n",
      "2019-10-13    55\n",
      "2019-10-20    55\n",
      "2019-10-27    55,             data\n",
      "date            \n",
      "2019-06-02    57\n",
      "2019-06-09    61\n",
      "2019-06-16    61\n",
      "2019-06-23    64\n",
      "2019-06-30    63,             data\n",
      "2016-01-31    15\n",
      "2016-02-07    15\n",
      "2016-02-14    20\n",
      "2016-02-21    17\n",
      "2016-02-28    19,             data\n",
      "date            \n",
      "2017-10-01    50\n",
      "2017-10-08    51\n",
      "2017-10-15    47\n",
      "2017-10-22    47\n",
      "2017-10-29    51,             data\n",
      "2019-04-28    59\n",
      "2019-05-05    54\n",
      "2019-05-12    52\n",
      "2019-05-19    55\n",
      "2019-05-26    56,             data\n",
      "date            \n",
      "2016-07-03    20\n",
      "2016-07-10    21\n",
      "2016-07-17    20\n",
      "2016-07-24    18\n",
      "2016-07-31    21,             data\n",
      "2016-07-31    21\n",
      "2016-08-07    19\n",
      "2016-08-14    16\n",
      "2016-08-21    20\n",
      "2016-08-28    20,             data\n",
      "2016-10-30    18\n",
      "2016-11-06    19\n",
      "2016-11-13    20\n",
      "2016-11-20    19\n",
      "2016-11-27    22,             data\n",
      "2018-02-25    57\n",
      "2018-03-04    60\n",
      "2018-03-11    56\n",
      "2018-03-18    58\n",
      "2018-03-25    53,             data\n",
      "2018-01-28    50\n",
      "2018-02-04    59\n",
      "2018-02-11    56\n",
      "2018-02-18    58\n",
      "2018-02-25    57,             data\n",
      "2016-03-27    24\n",
      "2016-04-03    19\n",
      "2016-04-10    19\n",
      "2016-04-17    19\n",
      "2016-04-24    18,             data\n",
      "2018-09-30    54\n",
      "2018-10-07    59\n",
      "2018-10-14    60\n",
      "2018-10-21    55\n",
      "2018-10-28    55,             data\n",
      "date            \n",
      "2016-10-02    20\n",
      "2016-10-09    19\n",
      "2016-10-16    19\n",
      "2016-10-23    19\n",
      "2016-10-30    18,             data\n",
      "2018-05-27    56\n",
      "2018-06-03    57\n",
      "2018-06-10    57\n",
      "2018-06-17    72\n",
      "2018-06-24    71,             data\n",
      "date            \n",
      "2019-12-01    51\n",
      "2019-12-08    55\n",
      "2019-12-15    52\n",
      "2019-12-22    56\n",
      "2019-12-29    54,             data\n",
      "date            \n",
      "2017-01-01    55\n",
      "2017-01-08    53\n",
      "2017-01-15    47\n",
      "2017-01-22    51\n",
      "2017-01-29    48,             data\n",
      "2016-11-27    22\n",
      "2016-12-04    41\n",
      "2016-12-11    42\n",
      "2016-12-18    42\n",
      "2016-12-25    46,             data\n",
      "2016-02-28    19\n",
      "2016-03-06    20\n",
      "2016-03-13    19\n",
      "2016-03-20    19\n",
      "2016-03-27    24,             data\n",
      "2017-01-29    48\n",
      "2017-02-05    54\n",
      "2017-02-12    50\n",
      "2017-02-19    52\n",
      "2017-02-26    53,             data\n",
      "2019-07-28    63\n",
      "2019-08-04    64\n",
      "2019-08-11    64\n",
      "2019-08-18    65\n",
      "2019-08-25    61,             data\n",
      "date            \n",
      "2017-07-02    51\n",
      "2017-07-09    50\n",
      "2017-07-16    45\n",
      "2017-07-23    49\n",
      "2017-07-30    47,             data\n",
      "2016-08-28    20\n",
      "2016-09-04    20\n",
      "2016-09-11    20\n",
      "2016-09-18    20\n",
      "2016-09-25    19,             data\n",
      "2017-07-30    47\n",
      "2017-08-06    47\n",
      "2017-08-13    51\n",
      "2017-08-20    50\n",
      "2017-08-27    49,             data\n",
      "2019-01-27    26\n",
      "2019-02-03    21\n",
      "2019-02-10    20\n",
      "2019-02-17    24\n",
      "2019-02-24    22,             data\n",
      "2017-08-27    49\n",
      "2017-09-03    50\n",
      "2017-09-10    50\n",
      "2017-09-17    49\n",
      "2017-09-24    47,             data\n",
      "2019-03-31    51\n",
      "2019-04-07    55\n",
      "2019-04-14    54\n",
      "2019-04-21    62\n",
      "2019-04-28    59,             data\n",
      "2017-04-30    46\n",
      "2017-05-07    42\n",
      "2017-05-14    44\n",
      "2017-05-21    46\n",
      "2017-05-28    44,             data\n",
      "2018-04-29    57\n",
      "2018-05-06    50\n",
      "2018-05-13    50\n",
      "2018-05-20    55\n",
      "2018-05-27    56,             data\n",
      "2019-06-30    63\n",
      "2019-07-07    64\n",
      "2019-07-14    63\n",
      "2019-07-21    61\n",
      "2019-07-28    63,             data\n",
      "2017-12-31    54\n",
      "2018-01-07    53\n",
      "2018-01-14    56\n",
      "2018-01-21    55\n",
      "2018-01-28    50,             data\n",
      "date            \n",
      "2019-03-03    21\n",
      "2019-03-10    21\n",
      "2019-03-17    22\n",
      "2019-03-24    23\n",
      "2019-03-31    51,             data\n",
      "date            \n",
      "2018-04-01    56\n",
      "2018-04-08    52\n",
      "2018-04-15    49\n",
      "2018-04-22    53\n",
      "2018-04-29    57,             data\n",
      "date            \n",
      "2016-01-03    17\n",
      "2016-01-10    18\n",
      "2016-01-17    17\n",
      "2016-01-24    16\n",
      "2016-01-31    15,             data\n",
      "2018-10-28    55\n",
      "2018-11-04    51\n",
      "2018-11-11    52\n",
      "2018-11-18    53\n",
      "2018-11-25    51]\n"
     ]
    }
   ],
   "source": [
    "import random # 렌덤으로  df1_nc를 섞어줌\n",
    "\n",
    "random.shuffle(df1_nc)\n",
    "\n",
    "print(df1_nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나는 지금 저 배열에서 데이터 프레임을 하나씩 꺼내 각 상황에 맞는 넘파이 식을 만들고 싶다....\n",
    "# .... 그래 그냥 배워야지...\n",
    "\n",
    "# = df_1_w[:df1_n-c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-88aaf0c211a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_1_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdf1_n\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "lst = [x for x in df_1_w[:df1_n-c]]\n",
    "test4 = np.array([[[]]])\n",
    "test4.append(test4,lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스의 자표를 알아내기...\n",
    "# 정 답이 없다면 차라리 어제 사용했던 날짜 게산장치를 이용하자. 그러면 될꺼야.\n",
    "# 달과  요일을  가져온다음 그걸 날짜 데이터 타입으로 변환? 아니지 이미 날짜 데이터 타입이니까...\n",
    "\n",
    "# 그러면 거기서 달 +1 한다음 거기다가 연길"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_month_data_1w_call (Input_date,n): # 이걸 응용 # 변환중....\n",
    "    forecast_target_month = datetime.timedelta(months=n)\n",
    "    Calculated_time = Input_date + forecast_target_month\n",
    "    return Calculated_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-46491da82f56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_1_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0ma2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_1_w\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0ma3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0ma3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# b=index_Shuffle_tracking(df_1_w)\n",
    "# b\n",
    "\n",
    "type(df_1_w[1].index[1].year)\n",
    "a1 = df_1_w[1].index[1].year\n",
    "a2 = df_1_w[1].index[1].month\n",
    "a3 = datetime(a1,a2,0,0,0,0)\n",
    "a3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그럼 플렌 2다 전통적인 시간 변경 기술...\n",
    "\n",
    "def Traditional_year_one_month_change(y, m):\n",
    "    if m >= 12:\n",
    "        m = 1\n",
    "        y = y + 1\n",
    "\n",
    "    else:\n",
    "        m = m +1\n",
    "        \n",
    "    return y, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 함수 테스트\n",
    "Traditional_year_one_month_change(2017,18)\n",
    "# 반복 사용은 for 문을 돌리자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arr = np.array([])\n",
    "# def index_Shuffle_tracking(shuffle_data):\n",
    "#     arr = np.array([])\n",
    "#     for learning_windows in shuffle_data:\n",
    "#         l_windows_y = learning_windows.index[1].year\n",
    "#         l_windows_m = learning_windows.index[1].month # 여길변경\n",
    "#         print(l_windows_y,l_windows_m)\n",
    "#         print(learning_windows.index[1])\n",
    "#         a = next_month_data_1w_call(l_windows_y+l_windows_y, 1)\n",
    "#         print(a)\n",
    "        \n",
    "#         arr = np.append(arr,np.array(df2[str(l_windows_y)+\"-\"+str(l_windows_m)]))\n",
    "#     return arr # 아 잠깐만 잠깐만... 이거 쓰기 힘들겠다... # 변경함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([])\n",
    "def index_Shuffle_tracking(shuffle_data): # 주의 :1달만 앞으로 당겨짐 좀더 다양하게 하고 싶으면 계선필요\n",
    "    arr = np.array([])\n",
    "    for learning_windows in shuffle_data:\n",
    "        l_windows_y = learning_windows.index[1].year\n",
    "        l_windows_m = learning_windows.index[1].month # 여길변경\n",
    "        nl_windows_y ,nl_windows_m = Traditional_year_one_month_change(l_windows_y,l_windows_m)\n",
    "        print(learning_windows.index[1])\n",
    "        print(nl_windows_y, nl_windows_m)\n",
    "        \n",
    "        arr = np.append(arr,np.array(df2[str(nl_windows_y)+\"-\"+str(nl_windows_m)]))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-07-08 00:00:00\n",
      "2018 8\n",
      "2018-12-09 00:00:00\n",
      "2019 1\n",
      "2019-01-06 00:00:00\n",
      "2019 2\n",
      "2019-09-08 00:00:00\n",
      "2019 10\n",
      "2017-06-04 00:00:00\n",
      "2017 7\n",
      "2017-11-05 00:00:00\n",
      "2017 12\n",
      "2016-06-05 00:00:00\n",
      "2016 7\n",
      "2017-04-09 00:00:00\n",
      "2017 5\n",
      "2017-12-10 00:00:00\n",
      "2018 1\n",
      "2017-03-05 00:00:00\n",
      "2017 4\n",
      "2016-05-08 00:00:00\n",
      "2016 6\n",
      "2019-11-03 00:00:00\n",
      "2019 12\n",
      "2018-09-09 00:00:00\n",
      "2018 10\n",
      "2018-08-05 00:00:00\n",
      "2018 9\n",
      "2019-10-06 00:00:00\n",
      "2019 11\n",
      "2019-06-09 00:00:00\n",
      "2019 7\n",
      "2016-02-07 00:00:00\n",
      "2016 3\n",
      "2017-10-08 00:00:00\n",
      "2017 11\n",
      "2019-05-05 00:00:00\n",
      "2019 6\n",
      "2016-07-10 00:00:00\n",
      "2016 8\n",
      "2016-08-07 00:00:00\n",
      "2016 9\n",
      "2016-11-06 00:00:00\n",
      "2016 12\n",
      "2018-03-04 00:00:00\n",
      "2018 4\n",
      "2018-02-04 00:00:00\n",
      "2018 3\n",
      "2016-04-03 00:00:00\n",
      "2016 5\n",
      "2018-10-07 00:00:00\n",
      "2018 11\n",
      "2016-10-09 00:00:00\n",
      "2016 11\n",
      "2018-06-03 00:00:00\n",
      "2018 7\n",
      "2019-12-08 00:00:00\n",
      "2020 1\n",
      "2017-01-08 00:00:00\n",
      "2017 2\n",
      "2016-12-04 00:00:00\n",
      "2017 1\n",
      "2016-03-06 00:00:00\n",
      "2016 4\n",
      "2017-02-05 00:00:00\n",
      "2017 3\n",
      "2019-08-04 00:00:00\n",
      "2019 9\n",
      "2017-07-09 00:00:00\n",
      "2017 8\n",
      "2016-09-04 00:00:00\n",
      "2016 10\n",
      "2017-08-06 00:00:00\n",
      "2017 9\n",
      "2019-02-03 00:00:00\n",
      "2019 3\n",
      "2017-09-03 00:00:00\n",
      "2017 10\n",
      "2019-04-07 00:00:00\n",
      "2019 5\n",
      "2017-05-07 00:00:00\n",
      "2017 6\n",
      "2018-05-06 00:00:00\n",
      "2018 6\n",
      "2019-07-07 00:00:00\n",
      "2019 8\n",
      "2018-01-07 00:00:00\n",
      "2018 2\n",
      "2019-03-10 00:00:00\n",
      "2019 4\n",
      "2018-04-08 00:00:00\n",
      "2018 5\n",
      "2016-01-10 00:00:00\n",
      "2016 2\n",
      "2018-11-04 00:00:00\n",
      "2018 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Indexing a DataFrame with a datetimelike index using a single string to slice the rows, like `frame[string]`, is deprecated and will be removed in a future version. Use `frame.loc[string]` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1391727., 1104803., 1201802., 1656195., 1008671., 1134068.,\n",
       "       1703495.,  977889.,  956036., 1075899., 1554413., 1456888.,\n",
       "       1527832., 1278604., 1456429., 1448067., 1389399., 1093217.,\n",
       "       1476218., 1664303., 1523928., 1343398., 1331709., 1366100.,\n",
       "       1492680., 1350390., 1309055., 1254833., 1272708., 1252080.,\n",
       "       1220695., 1469674., 1233640., 1459664., 1103506., 1587797.,\n",
       "       1078653., 1535641., 1165638., 1485684.,  991802., 1282093.,\n",
       "       1586299., 1045415., 1635066., 1238021., 1126250., 1324119.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y=index_Shuffle_tracking(df1_nc) # train_y는 테스트 데이터와 학습 데이터를 나누기 전의 y로 내가 정의한다.\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
       "         40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
       "         53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
       "         66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
       "         79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
       "         92,  93,  94,  95,  96,  97,  98,  99, 100]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 좋았어! 됬다. 드디어!\n",
    "#잠깐만 휴식하고 바로 셔플링 후 저 공식으로 계산하자\n",
    "# 잠시만 넘파이 셔플링 공식을 과연 쓸 수 있을까?\n",
    "a = np.array([range(1,101)])\n",
    "a\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 5, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.reshape() \n",
    "a = a.reshape(-1,5,1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 2],\n",
       "       [ 3],\n",
       "       [ 4],\n",
       "       [ 5],\n",
       "       [ 6],\n",
       "       [ 7],\n",
       "       [ 8],\n",
       "       [ 9],\n",
       "       [10]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([range(1,11)])\n",
    "b = b.reshape(-1,1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(a)\n",
    "# d역시 한계가 있다. 그냥 기존 방식을 쓰기로 하자 오늘은..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존의 방식은 단순 셔플링...  그다음 연결\n",
    "\n",
    "# 자 이제 y 도 대충 만들었고 이제 x만 어찌하면 된다...\n",
    "\n",
    "# 문제가... 저게... 뭐라고 해야하지?  인댁스가 겹치는 것이 생긴다... 그러면...\n",
    "# 판다스로 합치는 과정 없이 바로 넘파이 배열로 가자...\n",
    "\n",
    "def Pandas_NumPy_Transformation(data): # 파이썬 배열을 집어 넣는다.\n",
    "    PNT_Numpy_Array=([])\n",
    "    for Inside_pandas in data:\n",
    "        PNT_Numpy_Array = np.append(PNT_Numpy_Array,np.array(Inside_pandas))\n",
    "        \n",
    "    return PNT_Numpy_Array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([58., 58., 53., 52., 57., 49., 49., 51., 57., 61., 61., 60., 58.,\n",
       "       53., 26., 60., 57., 56., 57., 53., 44., 42., 44., 49., 47., 51.,\n",
       "       55., 48., 47., 45., 20., 19., 21., 17., 18., 48., 57., 52., 47.,\n",
       "       46., 46., 47., 47., 51., 54., 53., 57., 57., 57., 54., 17., 20.,\n",
       "       20., 19., 20., 55., 56., 56., 59., 53., 59., 58., 53., 52., 54.,\n",
       "       57., 57., 60., 64., 69., 53., 65., 55., 55., 55., 57., 61., 61.,\n",
       "       64., 63., 15., 15., 20., 17., 19., 50., 51., 47., 47., 51., 59.,\n",
       "       54., 52., 55., 56., 20., 21., 20., 18., 21., 21., 19., 16., 20.,\n",
       "       20., 18., 19., 20., 19., 22., 57., 60., 56., 58., 53., 50., 59.,\n",
       "       56., 58., 57., 24., 19., 19., 19., 18., 54., 59., 60., 55., 55.,\n",
       "       20., 19., 19., 19., 18., 56., 57., 57., 72., 71., 51., 55., 52.,\n",
       "       56., 54., 55., 53., 47., 51., 48., 22., 41., 42., 42., 46., 19.,\n",
       "       20., 19., 19., 24., 48., 54., 50., 52., 53., 63., 64., 64., 65.,\n",
       "       61., 51., 50., 45., 49., 47., 20., 20., 20., 20., 19., 47., 47.,\n",
       "       51., 50., 49., 26., 21., 20., 24., 22., 49., 50., 50., 49., 47.,\n",
       "       51., 55., 54., 62., 59., 46., 42., 44., 46., 44., 57., 50., 50.,\n",
       "       55., 56., 63., 64., 63., 61., 63., 54., 53., 56., 55., 50., 21.,\n",
       "       21., 22., 23., 51., 56., 52., 49., 53., 57., 17., 18., 17., 16.,\n",
       "       15., 55., 51., 52., 53., 51.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = Pandas_NumPy_Transformation(df1_nc)\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((48, 5, 1), (48, 1, 1))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_1 = train_x.reshape(-1,5,1)\n",
    "train_y_1 = train_y.reshape(-1,1,1)\n",
    "train_x_1.shape, train_y_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[58.]\n",
      "  [58.]\n",
      "  [53.]\n",
      "  [52.]\n",
      "  [57.]]\n",
      "\n",
      " [[49.]\n",
      "  [49.]\n",
      "  [51.]\n",
      "  [57.]\n",
      "  [61.]]\n",
      "\n",
      " [[61.]\n",
      "  [60.]\n",
      "  [58.]\n",
      "  [53.]\n",
      "  [26.]]\n",
      "\n",
      " [[60.]\n",
      "  [57.]\n",
      "  [56.]\n",
      "  [57.]\n",
      "  [53.]]\n",
      "\n",
      " [[44.]\n",
      "  [42.]\n",
      "  [44.]\n",
      "  [49.]\n",
      "  [47.]]\n",
      "\n",
      " [[51.]\n",
      "  [55.]\n",
      "  [48.]\n",
      "  [47.]\n",
      "  [45.]]\n",
      "\n",
      " [[20.]\n",
      "  [19.]\n",
      "  [21.]\n",
      "  [17.]\n",
      "  [18.]]\n",
      "\n",
      " [[48.]\n",
      "  [57.]\n",
      "  [52.]\n",
      "  [47.]\n",
      "  [46.]]\n",
      "\n",
      " [[46.]\n",
      "  [47.]\n",
      "  [47.]\n",
      "  [51.]\n",
      "  [54.]]\n",
      "\n",
      " [[53.]\n",
      "  [57.]\n",
      "  [57.]\n",
      "  [57.]\n",
      "  [54.]]\n",
      "\n",
      " [[17.]\n",
      "  [20.]\n",
      "  [20.]\n",
      "  [19.]\n",
      "  [20.]]\n",
      "\n",
      " [[55.]\n",
      "  [56.]\n",
      "  [56.]\n",
      "  [59.]\n",
      "  [53.]]\n",
      "\n",
      " [[59.]\n",
      "  [58.]\n",
      "  [53.]\n",
      "  [52.]\n",
      "  [54.]]\n",
      "\n",
      " [[57.]\n",
      "  [57.]\n",
      "  [60.]\n",
      "  [64.]\n",
      "  [69.]]\n",
      "\n",
      " [[53.]\n",
      "  [65.]\n",
      "  [55.]\n",
      "  [55.]\n",
      "  [55.]]\n",
      "\n",
      " [[57.]\n",
      "  [61.]\n",
      "  [61.]\n",
      "  [64.]\n",
      "  [63.]]\n",
      "\n",
      " [[15.]\n",
      "  [15.]\n",
      "  [20.]\n",
      "  [17.]\n",
      "  [19.]]\n",
      "\n",
      " [[50.]\n",
      "  [51.]\n",
      "  [47.]\n",
      "  [47.]\n",
      "  [51.]]\n",
      "\n",
      " [[59.]\n",
      "  [54.]\n",
      "  [52.]\n",
      "  [55.]\n",
      "  [56.]]\n",
      "\n",
      " [[20.]\n",
      "  [21.]\n",
      "  [20.]\n",
      "  [18.]\n",
      "  [21.]]\n",
      "\n",
      " [[21.]\n",
      "  [19.]\n",
      "  [16.]\n",
      "  [20.]\n",
      "  [20.]]\n",
      "\n",
      " [[18.]\n",
      "  [19.]\n",
      "  [20.]\n",
      "  [19.]\n",
      "  [22.]]\n",
      "\n",
      " [[57.]\n",
      "  [60.]\n",
      "  [56.]\n",
      "  [58.]\n",
      "  [53.]]\n",
      "\n",
      " [[50.]\n",
      "  [59.]\n",
      "  [56.]\n",
      "  [58.]\n",
      "  [57.]]\n",
      "\n",
      " [[24.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [18.]]\n",
      "\n",
      " [[54.]\n",
      "  [59.]\n",
      "  [60.]\n",
      "  [55.]\n",
      "  [55.]]\n",
      "\n",
      " [[20.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [18.]]\n",
      "\n",
      " [[56.]\n",
      "  [57.]\n",
      "  [57.]\n",
      "  [72.]\n",
      "  [71.]]\n",
      "\n",
      " [[51.]\n",
      "  [55.]\n",
      "  [52.]\n",
      "  [56.]\n",
      "  [54.]]\n",
      "\n",
      " [[55.]\n",
      "  [53.]\n",
      "  [47.]\n",
      "  [51.]\n",
      "  [48.]]\n",
      "\n",
      " [[22.]\n",
      "  [41.]\n",
      "  [42.]\n",
      "  [42.]\n",
      "  [46.]]\n",
      "\n",
      " [[19.]\n",
      "  [20.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [24.]]\n",
      "\n",
      " [[48.]\n",
      "  [54.]\n",
      "  [50.]\n",
      "  [52.]\n",
      "  [53.]]\n",
      "\n",
      " [[63.]\n",
      "  [64.]\n",
      "  [64.]\n",
      "  [65.]\n",
      "  [61.]]\n",
      "\n",
      " [[51.]\n",
      "  [50.]\n",
      "  [45.]\n",
      "  [49.]\n",
      "  [47.]]\n",
      "\n",
      " [[20.]\n",
      "  [20.]\n",
      "  [20.]\n",
      "  [20.]\n",
      "  [19.]]\n",
      "\n",
      " [[47.]\n",
      "  [47.]\n",
      "  [51.]\n",
      "  [50.]\n",
      "  [49.]]\n",
      "\n",
      " [[26.]\n",
      "  [21.]\n",
      "  [20.]\n",
      "  [24.]\n",
      "  [22.]]\n",
      "\n",
      " [[49.]\n",
      "  [50.]\n",
      "  [50.]\n",
      "  [49.]\n",
      "  [47.]]\n",
      "\n",
      " [[51.]\n",
      "  [55.]\n",
      "  [54.]\n",
      "  [62.]\n",
      "  [59.]]\n",
      "\n",
      " [[46.]\n",
      "  [42.]\n",
      "  [44.]\n",
      "  [46.]\n",
      "  [44.]]\n",
      "\n",
      " [[57.]\n",
      "  [50.]\n",
      "  [50.]\n",
      "  [55.]\n",
      "  [56.]]\n",
      "\n",
      " [[63.]\n",
      "  [64.]\n",
      "  [63.]\n",
      "  [61.]\n",
      "  [63.]]\n",
      "\n",
      " [[54.]\n",
      "  [53.]\n",
      "  [56.]\n",
      "  [55.]\n",
      "  [50.]]\n",
      "\n",
      " [[21.]\n",
      "  [21.]\n",
      "  [22.]\n",
      "  [23.]\n",
      "  [51.]]\n",
      "\n",
      " [[56.]\n",
      "  [52.]\n",
      "  [49.]\n",
      "  [53.]\n",
      "  [57.]]\n",
      "\n",
      " [[17.]\n",
      "  [18.]\n",
      "  [17.]\n",
      "  [16.]\n",
      "  [15.]]\n",
      "\n",
      " [[55.]\n",
      "  [51.]\n",
      "  [52.]\n",
      "  [53.]\n",
      "  [51.]]]\n",
      "[[[1391727.]]\n",
      "\n",
      " [[1104803.]]\n",
      "\n",
      " [[1201802.]]\n",
      "\n",
      " [[1656195.]]\n",
      "\n",
      " [[1008671.]]\n",
      "\n",
      " [[1134068.]]\n",
      "\n",
      " [[1703495.]]\n",
      "\n",
      " [[ 977889.]]\n",
      "\n",
      " [[ 956036.]]\n",
      "\n",
      " [[1075899.]]\n",
      "\n",
      " [[1554413.]]\n",
      "\n",
      " [[1456888.]]\n",
      "\n",
      " [[1527832.]]\n",
      "\n",
      " [[1278604.]]\n",
      "\n",
      " [[1456429.]]\n",
      "\n",
      " [[1448067.]]\n",
      "\n",
      " [[1389399.]]\n",
      "\n",
      " [[1093217.]]\n",
      "\n",
      " [[1476218.]]\n",
      "\n",
      " [[1664303.]]\n",
      "\n",
      " [[1523928.]]\n",
      "\n",
      " [[1343398.]]\n",
      "\n",
      " [[1331709.]]\n",
      "\n",
      " [[1366100.]]\n",
      "\n",
      " [[1492680.]]\n",
      "\n",
      " [[1350390.]]\n",
      "\n",
      " [[1309055.]]\n",
      "\n",
      " [[1254833.]]\n",
      "\n",
      " [[1272708.]]\n",
      "\n",
      " [[1252080.]]\n",
      "\n",
      " [[1220695.]]\n",
      "\n",
      " [[1469674.]]\n",
      "\n",
      " [[1233640.]]\n",
      "\n",
      " [[1459664.]]\n",
      "\n",
      " [[1103506.]]\n",
      "\n",
      " [[1587797.]]\n",
      "\n",
      " [[1078653.]]\n",
      "\n",
      " [[1535641.]]\n",
      "\n",
      " [[1165638.]]\n",
      "\n",
      " [[1485684.]]\n",
      "\n",
      " [[ 991802.]]\n",
      "\n",
      " [[1282093.]]\n",
      "\n",
      " [[1586299.]]\n",
      "\n",
      " [[1045415.]]\n",
      "\n",
      " [[1635066.]]\n",
      "\n",
      " [[1238021.]]\n",
      "\n",
      " [[1126250.]]\n",
      "\n",
      " [[1324119.]]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x_1)\n",
    "print(train_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 이걸 응용하자.\n",
    "\n",
    "# split train and test data # 데이터 나누기\n",
    "# row = int(round(result.shape[0]*0.9))\n",
    "# train = result[:row, :]\n",
    "# np.random.shuffle(train)\n",
    "\n",
    "row = int(round(train_x_1.shape[0]*0.9))\n",
    "x_train = train_x_1[:row, :]\n",
    "y_train = train_y_1[:row, :]\n",
    "\n",
    "x_test = train_x_1[row:,:]\n",
    "y_test = train_y_1[row:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[58.]\n",
      "  [58.]\n",
      "  [53.]\n",
      "  [52.]\n",
      "  [57.]]\n",
      "\n",
      " [[49.]\n",
      "  [49.]\n",
      "  [51.]\n",
      "  [57.]\n",
      "  [61.]]\n",
      "\n",
      " [[61.]\n",
      "  [60.]\n",
      "  [58.]\n",
      "  [53.]\n",
      "  [26.]]\n",
      "\n",
      " [[60.]\n",
      "  [57.]\n",
      "  [56.]\n",
      "  [57.]\n",
      "  [53.]]\n",
      "\n",
      " [[44.]\n",
      "  [42.]\n",
      "  [44.]\n",
      "  [49.]\n",
      "  [47.]]\n",
      "\n",
      " [[51.]\n",
      "  [55.]\n",
      "  [48.]\n",
      "  [47.]\n",
      "  [45.]]\n",
      "\n",
      " [[20.]\n",
      "  [19.]\n",
      "  [21.]\n",
      "  [17.]\n",
      "  [18.]]\n",
      "\n",
      " [[48.]\n",
      "  [57.]\n",
      "  [52.]\n",
      "  [47.]\n",
      "  [46.]]\n",
      "\n",
      " [[46.]\n",
      "  [47.]\n",
      "  [47.]\n",
      "  [51.]\n",
      "  [54.]]\n",
      "\n",
      " [[53.]\n",
      "  [57.]\n",
      "  [57.]\n",
      "  [57.]\n",
      "  [54.]]\n",
      "\n",
      " [[17.]\n",
      "  [20.]\n",
      "  [20.]\n",
      "  [19.]\n",
      "  [20.]]\n",
      "\n",
      " [[55.]\n",
      "  [56.]\n",
      "  [56.]\n",
      "  [59.]\n",
      "  [53.]]\n",
      "\n",
      " [[59.]\n",
      "  [58.]\n",
      "  [53.]\n",
      "  [52.]\n",
      "  [54.]]\n",
      "\n",
      " [[57.]\n",
      "  [57.]\n",
      "  [60.]\n",
      "  [64.]\n",
      "  [69.]]\n",
      "\n",
      " [[53.]\n",
      "  [65.]\n",
      "  [55.]\n",
      "  [55.]\n",
      "  [55.]]\n",
      "\n",
      " [[57.]\n",
      "  [61.]\n",
      "  [61.]\n",
      "  [64.]\n",
      "  [63.]]\n",
      "\n",
      " [[15.]\n",
      "  [15.]\n",
      "  [20.]\n",
      "  [17.]\n",
      "  [19.]]\n",
      "\n",
      " [[50.]\n",
      "  [51.]\n",
      "  [47.]\n",
      "  [47.]\n",
      "  [51.]]\n",
      "\n",
      " [[59.]\n",
      "  [54.]\n",
      "  [52.]\n",
      "  [55.]\n",
      "  [56.]]\n",
      "\n",
      " [[20.]\n",
      "  [21.]\n",
      "  [20.]\n",
      "  [18.]\n",
      "  [21.]]\n",
      "\n",
      " [[21.]\n",
      "  [19.]\n",
      "  [16.]\n",
      "  [20.]\n",
      "  [20.]]\n",
      "\n",
      " [[18.]\n",
      "  [19.]\n",
      "  [20.]\n",
      "  [19.]\n",
      "  [22.]]\n",
      "\n",
      " [[57.]\n",
      "  [60.]\n",
      "  [56.]\n",
      "  [58.]\n",
      "  [53.]]\n",
      "\n",
      " [[50.]\n",
      "  [59.]\n",
      "  [56.]\n",
      "  [58.]\n",
      "  [57.]]\n",
      "\n",
      " [[24.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [18.]]\n",
      "\n",
      " [[54.]\n",
      "  [59.]\n",
      "  [60.]\n",
      "  [55.]\n",
      "  [55.]]\n",
      "\n",
      " [[20.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [18.]]\n",
      "\n",
      " [[56.]\n",
      "  [57.]\n",
      "  [57.]\n",
      "  [72.]\n",
      "  [71.]]\n",
      "\n",
      " [[51.]\n",
      "  [55.]\n",
      "  [52.]\n",
      "  [56.]\n",
      "  [54.]]\n",
      "\n",
      " [[55.]\n",
      "  [53.]\n",
      "  [47.]\n",
      "  [51.]\n",
      "  [48.]]\n",
      "\n",
      " [[22.]\n",
      "  [41.]\n",
      "  [42.]\n",
      "  [42.]\n",
      "  [46.]]\n",
      "\n",
      " [[19.]\n",
      "  [20.]\n",
      "  [19.]\n",
      "  [19.]\n",
      "  [24.]]\n",
      "\n",
      " [[48.]\n",
      "  [54.]\n",
      "  [50.]\n",
      "  [52.]\n",
      "  [53.]]\n",
      "\n",
      " [[63.]\n",
      "  [64.]\n",
      "  [64.]\n",
      "  [65.]\n",
      "  [61.]]\n",
      "\n",
      " [[51.]\n",
      "  [50.]\n",
      "  [45.]\n",
      "  [49.]\n",
      "  [47.]]\n",
      "\n",
      " [[20.]\n",
      "  [20.]\n",
      "  [20.]\n",
      "  [20.]\n",
      "  [19.]]\n",
      "\n",
      " [[47.]\n",
      "  [47.]\n",
      "  [51.]\n",
      "  [50.]\n",
      "  [49.]]\n",
      "\n",
      " [[26.]\n",
      "  [21.]\n",
      "  [20.]\n",
      "  [24.]\n",
      "  [22.]]\n",
      "\n",
      " [[49.]\n",
      "  [50.]\n",
      "  [50.]\n",
      "  [49.]\n",
      "  [47.]]\n",
      "\n",
      " [[51.]\n",
      "  [55.]\n",
      "  [54.]\n",
      "  [62.]\n",
      "  [59.]]\n",
      "\n",
      " [[46.]\n",
      "  [42.]\n",
      "  [44.]\n",
      "  [46.]\n",
      "  [44.]]\n",
      "\n",
      " [[57.]\n",
      "  [50.]\n",
      "  [50.]\n",
      "  [55.]\n",
      "  [56.]]\n",
      "\n",
      " [[63.]\n",
      "  [64.]\n",
      "  [63.]\n",
      "  [61.]\n",
      "  [63.]]]\n",
      "[[[1391727.]]\n",
      "\n",
      " [[1104803.]]\n",
      "\n",
      " [[1201802.]]\n",
      "\n",
      " [[1656195.]]\n",
      "\n",
      " [[1008671.]]\n",
      "\n",
      " [[1134068.]]\n",
      "\n",
      " [[1703495.]]\n",
      "\n",
      " [[ 977889.]]\n",
      "\n",
      " [[ 956036.]]\n",
      "\n",
      " [[1075899.]]\n",
      "\n",
      " [[1554413.]]\n",
      "\n",
      " [[1456888.]]\n",
      "\n",
      " [[1527832.]]\n",
      "\n",
      " [[1278604.]]\n",
      "\n",
      " [[1456429.]]\n",
      "\n",
      " [[1448067.]]\n",
      "\n",
      " [[1389399.]]\n",
      "\n",
      " [[1093217.]]\n",
      "\n",
      " [[1476218.]]\n",
      "\n",
      " [[1664303.]]\n",
      "\n",
      " [[1523928.]]\n",
      "\n",
      " [[1343398.]]\n",
      "\n",
      " [[1331709.]]\n",
      "\n",
      " [[1366100.]]\n",
      "\n",
      " [[1492680.]]\n",
      "\n",
      " [[1350390.]]\n",
      "\n",
      " [[1309055.]]\n",
      "\n",
      " [[1254833.]]\n",
      "\n",
      " [[1272708.]]\n",
      "\n",
      " [[1252080.]]\n",
      "\n",
      " [[1220695.]]\n",
      "\n",
      " [[1469674.]]\n",
      "\n",
      " [[1233640.]]\n",
      "\n",
      " [[1459664.]]\n",
      "\n",
      " [[1103506.]]\n",
      "\n",
      " [[1587797.]]\n",
      "\n",
      " [[1078653.]]\n",
      "\n",
      " [[1535641.]]\n",
      "\n",
      " [[1165638.]]\n",
      "\n",
      " [[1485684.]]\n",
      "\n",
      " [[ 991802.]]\n",
      "\n",
      " [[1282093.]]\n",
      "\n",
      " [[1586299.]]]\n",
      "[[[54.]\n",
      "  [53.]\n",
      "  [56.]\n",
      "  [55.]\n",
      "  [50.]]\n",
      "\n",
      " [[21.]\n",
      "  [21.]\n",
      "  [22.]\n",
      "  [23.]\n",
      "  [51.]]\n",
      "\n",
      " [[56.]\n",
      "  [52.]\n",
      "  [49.]\n",
      "  [53.]\n",
      "  [57.]]\n",
      "\n",
      " [[17.]\n",
      "  [18.]\n",
      "  [17.]\n",
      "  [16.]\n",
      "  [15.]]\n",
      "\n",
      " [[55.]\n",
      "  [51.]\n",
      "  [52.]\n",
      "  [53.]\n",
      "  [51.]]]\n",
      "[[[1045415.]]\n",
      "\n",
      " [[1635066.]]\n",
      "\n",
      " [[1238021.]]\n",
      "\n",
      " [[1126250.]]\n",
      "\n",
      " [[1324119.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((43, 5, 1), (43, 1, 1), (5, 5, 1), (5, 1, 1))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(y_train)\n",
    "\n",
    "print(x_test)\n",
    "print(y_test)\n",
    "\n",
    "x_train.shape , y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "5/5 [==============================] - 4s 220ms/step - loss: 1799458084181.3333 - val_loss: 1664147128320.0000\n",
      "Epoch 2/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1830909007189.3333 - val_loss: 1664139788288.0000\n",
      "Epoch 3/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1855180963840.0000 - val_loss: 1664132317184.0000\n",
      "Epoch 4/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1766193692672.0000 - val_loss: 1664127860736.0000\n",
      "Epoch 5/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1778590045525.3333 - val_loss: 1664125239296.0000\n",
      "Epoch 6/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1863945158656.0000 - val_loss: 1664123404288.0000\n",
      "Epoch 7/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1830725790378.6667 - val_loss: 1664121962496.0000\n",
      "Epoch 8/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1844689939114.6667 - val_loss: 1664120782848.0000\n",
      "Epoch 9/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1832221977258.6667 - val_loss: 1664119734272.0000\n",
      "Epoch 10/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1821328474112.0000 - val_loss: 1664118685696.0000\n",
      "Epoch 11/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1750323778901.3333 - val_loss: 1664117768192.0000\n",
      "Epoch 12/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1881886818304.0000 - val_loss: 1664116850688.0000\n",
      "Epoch 13/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1828484437333.3333 - val_loss: 1664115933184.0000\n",
      "Epoch 14/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1884750675968.0000 - val_loss: 1664115015680.0000\n",
      "Epoch 15/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1803390440789.3333 - val_loss: 1664113967104.0000\n",
      "Epoch 16/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1800322940928.0000 - val_loss: 1664113311744.0000\n",
      "Epoch 17/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1826686697472.0000 - val_loss: 1664112394240.0000\n",
      "Epoch 18/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1811379191808.0000 - val_loss: 1664111345664.0000\n",
      "Epoch 19/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1850829198677.3333 - val_loss: 1664110821376.0000\n",
      "Epoch 20/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1705208250368.0000 - val_loss: 1664109772800.0000\n",
      "Epoch 21/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1836297180501.3333 - val_loss: 1664108855296.0000\n",
      "Epoch 22/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1854705063253.3333 - val_loss: 1664108331008.0000\n",
      "Epoch 23/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1769438838784.0000 - val_loss: 1664107282432.0000\n",
      "Epoch 24/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1844244534613.3333 - val_loss: 1664106627072.0000\n",
      "Epoch 25/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1858374970026.6667 - val_loss: 1664105709568.0000\n",
      "Epoch 26/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1793639885482.6667 - val_loss: 1664104792064.0000\n",
      "Epoch 27/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1799226654720.0000 - val_loss: 1664104136704.0000\n",
      "Epoch 28/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1726000813397.3333 - val_loss: 1664103088128.0000\n",
      "Epoch 29/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1806308824405.3333 - val_loss: 1664102301696.0000\n",
      "Epoch 30/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1828256109909.3333 - val_loss: 1664101646336.0000\n",
      "Epoch 31/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1799924241749.3333 - val_loss: 1664100728832.0000\n",
      "Epoch 32/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1858361862826.6667 - val_loss: 1664099942400.0000\n",
      "Epoch 33/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1775952527360.0000 - val_loss: 1664098893824.0000\n",
      "Epoch 34/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1834742338901.3333 - val_loss: 1664098238464.0000\n",
      "Epoch 35/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1847126152533.3333 - val_loss: 1664097452032.0000\n",
      "Epoch 36/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1764599442090.6667 - val_loss: 1664096665600.0000\n",
      "Epoch 37/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1751307299498.6667 - val_loss: 1664095879168.0000\n",
      "Epoch 38/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1791125356544.0000 - val_loss: 1664094961664.0000\n",
      "Epoch 39/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1841659183104.0000 - val_loss: 1664094175232.0000\n",
      "Epoch 40/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1872463243946.6667 - val_loss: 1664093257728.0000\n",
      "Epoch 41/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1840315083434.6667 - val_loss: 1664092340224.0000\n",
      "Epoch 42/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1823285204309.3333 - val_loss: 1664091815936.0000\n",
      "Epoch 43/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1807754286421.3333 - val_loss: 1664090767360.0000\n",
      "Epoch 44/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1819130243754.6667 - val_loss: 1664090112000.0000\n",
      "Epoch 45/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1812971913216.0000 - val_loss: 1664089194496.0000\n",
      "Epoch 46/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1811373839701.3333 - val_loss: 1664088276992.0000\n",
      "Epoch 47/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1813960873301.3333 - val_loss: 1664087621632.0000\n",
      "Epoch 48/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1853053337600.0000 - val_loss: 1664086704128.0000\n",
      "Epoch 49/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1835489842517.3333 - val_loss: 1664086048768.0000\n",
      "Epoch 50/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1753326441813.3333 - val_loss: 1664085131264.0000\n",
      "Epoch 51/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1786313288362.6667 - val_loss: 1664084082688.0000\n",
      "Epoch 52/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1869879596373.3333 - val_loss: 1664083558400.0000\n",
      "Epoch 53/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1791736938496.0000 - val_loss: 1664082509824.0000\n",
      "Epoch 54/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1826860892160.0000 - val_loss: 1664081723392.0000\n",
      "Epoch 55/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1798884731562.6667 - val_loss: 1664080936960.0000\n",
      "Epoch 56/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1854122885120.0000 - val_loss: 1664079888384.0000\n",
      "Epoch 57/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1762355249152.0000 - val_loss: 1664079233024.0000\n",
      "Epoch 58/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1858193959594.6667 - val_loss: 1664078315520.0000\n",
      "Epoch 59/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1783913556650.6667 - val_loss: 1664077529088.0000\n",
      "Epoch 60/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1778548255402.6667 - val_loss: 1664076742656.0000\n",
      "Epoch 61/500\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 1872258684245.3333 - val_loss: 1664075825152.0000\n",
      "Epoch 62/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1809596416000.0000 - val_loss: 1664075169792.0000\n",
      "Epoch 63/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1858348275029.3333 - val_loss: 1664074121216.0000\n",
      "Epoch 64/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1797037948928.0000 - val_loss: 1664073596928.0000\n",
      "Epoch 65/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1707141846357.3333 - val_loss: 1664072548352.0000\n",
      "Epoch 66/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1856359475882.6667 - val_loss: 1664071630848.0000\n",
      "Epoch 67/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1809148215296.0000 - val_loss: 1664070975488.0000\n",
      "Epoch 68/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1903815994026.6667 - val_loss: 1664070057984.0000\n",
      "Epoch 69/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1845621795498.6667 - val_loss: 1664069533696.0000\n",
      "Epoch 70/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1859876399786.6667 - val_loss: 1664068485120.0000\n",
      "Epoch 71/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1834360700928.0000 - val_loss: 1664067829760.0000\n",
      "Epoch 72/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1832897347584.0000 - val_loss: 1664066912256.0000\n",
      "Epoch 73/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1754592444416.0000 - val_loss: 1664065863680.0000\n",
      "Epoch 74/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1793130779989.3333 - val_loss: 1664065339392.0000\n",
      "Epoch 75/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1800884125696.0000 - val_loss: 1664064421888.0000\n",
      "Epoch 76/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1804108059989.3333 - val_loss: 1664063504384.0000\n",
      "Epoch 77/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1808734377301.3333 - val_loss: 1664062717952.0000\n",
      "Epoch 78/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1846720637610.6667 - val_loss: 1664061931520.0000\n",
      "Epoch 79/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1854293082112.0000 - val_loss: 1664061145088.0000\n",
      "Epoch 80/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1758298658133.3333 - val_loss: 1664060096512.0000\n",
      "Epoch 81/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1793681894058.6667 - val_loss: 1664059441152.0000\n",
      "Epoch 82/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1814929997824.0000 - val_loss: 1664058654720.0000\n",
      "Epoch 83/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1783831811413.3333 - val_loss: 1664057606144.0000\n",
      "Epoch 84/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1815333743274.6667 - val_loss: 1664057081856.0000\n",
      "Epoch 85/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1824760965802.6667 - val_loss: 1664056164352.0000\n",
      "Epoch 86/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1774137573376.0000 - val_loss: 1664055115776.0000\n",
      "Epoch 87/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1785965816490.6667 - val_loss: 1664054329344.0000\n",
      "Epoch 88/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1822583444821.3333 - val_loss: 1664053411840.0000\n",
      "Epoch 89/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1855977357312.0000 - val_loss: 1664052887552.0000\n",
      "Epoch 90/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1808938543786.6667 - val_loss: 1664051970048.0000\n",
      "Epoch 91/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1783236591616.0000 - val_loss: 1664051314688.0000\n",
      "Epoch 92/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1807881317034.6667 - val_loss: 1664050266112.0000\n",
      "Epoch 93/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1874700686677.3333 - val_loss: 1664049217536.0000\n",
      "Epoch 94/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1853048728234.6667 - val_loss: 1664048693248.0000\n",
      "Epoch 95/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1818713194496.0000 - val_loss: 1664047906816.0000\n",
      "Epoch 96/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1857195584170.6667 - val_loss: 1664047251456.0000\n",
      "Epoch 97/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1799943378261.3333 - val_loss: 1664046202880.0000\n",
      "Epoch 98/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1843716096000.0000 - val_loss: 1664045285376.0000\n",
      "Epoch 99/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1750117580800.0000 - val_loss: 1664044761088.0000\n",
      "Epoch 100/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1848013728426.6667 - val_loss: 1664043712512.0000\n",
      "Epoch 101/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1833110667264.0000 - val_loss: 1664042926080.0000\n",
      "Epoch 102/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1837498127701.3333 - val_loss: 1664042139648.0000\n",
      "Epoch 103/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1830830822741.3333 - val_loss: 1664041222144.0000\n",
      "Epoch 104/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1856936869888.0000 - val_loss: 1664040435712.0000\n",
      "Epoch 105/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1792459844266.6667 - val_loss: 1664039518208.0000\n",
      "Epoch 106/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1871277435562.6667 - val_loss: 1664038862848.0000\n",
      "Epoch 107/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1784444354560.0000 - val_loss: 1664037945344.0000\n",
      "Epoch 108/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1833840279552.0000 - val_loss: 1664037027840.0000\n",
      "Epoch 109/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1881565102080.0000 - val_loss: 1664036241408.0000\n",
      "Epoch 110/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1910943602005.3333 - val_loss: 1664035323904.0000\n",
      "Epoch 111/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1875188711424.0000 - val_loss: 1664034799616.0000\n",
      "Epoch 112/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1963728546474.6667 - val_loss: 1664033751040.0000\n",
      "Epoch 113/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1920011294037.3333 - val_loss: 1664033226752.0000\n",
      "Epoch 114/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1802729138858.6667 - val_loss: 1664032178176.0000\n",
      "Epoch 115/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1792947803477.3333 - val_loss: 1664031129600.0000\n",
      "Epoch 116/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1803380806997.3333 - val_loss: 1664030605312.0000\n",
      "Epoch 117/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1775038627840.0000 - val_loss: 1664029556736.0000\n",
      "Epoch 118/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1759029668522.6667 - val_loss: 1664028770304.0000\n",
      "Epoch 119/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1759340614997.3333 - val_loss: 1664027983872.0000\n",
      "Epoch 120/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1732892622848.0000 - val_loss: 1664027066368.0000\n",
      "Epoch 121/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1871584668330.6667 - val_loss: 1664026411008.0000\n",
      "Epoch 122/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1832227482282.6667 - val_loss: 1664025362432.0000\n",
      "Epoch 123/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1795459885738.6667 - val_loss: 1664024707072.0000\n",
      "Epoch 124/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1714706011477.3333 - val_loss: 1664023789568.0000\n",
      "Epoch 125/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1798256831146.6667 - val_loss: 1664023003136.0000\n",
      "Epoch 126/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1854994361002.6667 - val_loss: 1664022347776.0000\n",
      "Epoch 127/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1815137288192.0000 - val_loss: 1664021299200.0000\n",
      "Epoch 128/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1785560629248.0000 - val_loss: 1664020512768.0000\n",
      "Epoch 129/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1826279413077.3333 - val_loss: 1664019857408.0000\n",
      "Epoch 130/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1810398642176.0000 - val_loss: 1664018808832.0000\n",
      "Epoch 131/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1788137832448.0000 - val_loss: 1664018022400.0000\n",
      "Epoch 132/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1799943116117.3333 - val_loss: 1664017104896.0000\n",
      "Epoch 133/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 18ms/step - loss: 1880340955136.0000 - val_loss: 1664016449536.0000\n",
      "Epoch 134/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1785646634325.3333 - val_loss: 1664015663104.0000\n",
      "Epoch 135/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1827566649344.0000 - val_loss: 1664014614528.0000\n",
      "Epoch 136/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1779826666154.6667 - val_loss: 1664013959168.0000\n",
      "Epoch 137/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1724780751530.6667 - val_loss: 1664013041664.0000\n",
      "Epoch 138/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1791055713621.3333 - val_loss: 1664012124160.0000\n",
      "Epoch 139/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1804842085034.6667 - val_loss: 1664011468800.0000\n",
      "Epoch 140/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1858330405546.6667 - val_loss: 1664010551296.0000\n",
      "Epoch 141/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1842339774464.0000 - val_loss: 1664009895936.0000\n",
      "Epoch 142/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1852957982720.0000 - val_loss: 1664008978432.0000\n",
      "Epoch 143/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1815581491200.0000 - val_loss: 1664008323072.0000\n",
      "Epoch 144/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1821750045354.6667 - val_loss: 1664007405568.0000\n",
      "Epoch 145/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1764832357034.6667 - val_loss: 1664006488064.0000\n",
      "Epoch 146/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1847597247146.6667 - val_loss: 1664005832704.0000\n",
      "Epoch 147/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1782380735146.6667 - val_loss: 1664004784128.0000\n",
      "Epoch 148/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1776265723904.0000 - val_loss: 1664004128768.0000\n",
      "Epoch 149/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1777460619946.6667 - val_loss: 1664003342336.0000\n",
      "Epoch 150/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1841042314581.3333 - val_loss: 1664002293760.0000\n",
      "Epoch 151/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1904394392917.3333 - val_loss: 1664001638400.0000\n",
      "Epoch 152/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1800087470080.0000 - val_loss: 1664000720896.0000\n",
      "Epoch 153/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1746637182293.3333 - val_loss: 1663999934464.0000\n",
      "Epoch 154/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1863035715584.0000 - val_loss: 1663999016960.0000\n",
      "Epoch 155/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1817781469184.0000 - val_loss: 1663998099456.0000\n",
      "Epoch 156/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1788396918101.3333 - val_loss: 1663997444096.0000\n",
      "Epoch 157/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1875430430037.3333 - val_loss: 1663996526592.0000\n",
      "Epoch 158/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1751968295594.6667 - val_loss: 1663995740160.0000\n",
      "Epoch 159/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1839014608896.0000 - val_loss: 1663994953728.0000\n",
      "Epoch 160/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1859797734741.3333 - val_loss: 1663993905152.0000\n",
      "Epoch 161/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1831570418346.6667 - val_loss: 1663993380864.0000\n",
      "Epoch 162/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1876908485290.6667 - val_loss: 1663992332288.0000\n",
      "Epoch 163/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1842087635626.6667 - val_loss: 1663991808000.0000\n",
      "Epoch 164/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1828734588245.3333 - val_loss: 1663990759424.0000\n",
      "Epoch 165/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1824392063658.6667 - val_loss: 1663989841920.0000\n",
      "Epoch 166/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1803547683498.6667 - val_loss: 1663989186560.0000\n",
      "Epoch 167/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1751208645973.3333 - val_loss: 1663988269056.0000\n",
      "Epoch 168/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1832483007146.6667 - val_loss: 1663987613696.0000\n",
      "Epoch 169/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1827892516181.3333 - val_loss: 1663986696192.0000\n",
      "Epoch 170/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1741929447424.0000 - val_loss: 1663985647616.0000\n",
      "Epoch 171/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1791574605824.0000 - val_loss: 1663984992256.0000\n",
      "Epoch 172/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1815774538410.6667 - val_loss: 1663984074752.0000\n",
      "Epoch 173/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1826010759168.0000 - val_loss: 1663983550464.0000\n",
      "Epoch 174/500\n",
      "5/5 [==============================] - 0s 117ms/step - loss: 1826281248085.3333 - val_loss: 1663982501888.0000\n",
      "Epoch 175/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1809304758954.6667 - val_loss: 1663981846528.0000\n",
      "Epoch 176/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1770465918976.0000 - val_loss: 1663980797952.0000\n",
      "Epoch 177/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1911586837845.3333 - val_loss: 1663979749376.0000\n",
      "Epoch 178/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1757034796373.3333 - val_loss: 1663979225088.0000\n",
      "Epoch 179/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1796325856597.3333 - val_loss: 1663978307584.0000\n",
      "Epoch 180/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1909444618922.6667 - val_loss: 1663977652224.0000\n",
      "Epoch 181/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1899319678293.3333 - val_loss: 1663976734720.0000\n",
      "Epoch 182/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1778340462592.0000 - val_loss: 1663975817216.0000\n",
      "Epoch 183/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1878599488853.3333 - val_loss: 1663975030784.0000\n",
      "Epoch 184/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1906280912213.3333 - val_loss: 1663974244352.0000\n",
      "Epoch 185/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1822717553322.6667 - val_loss: 1663973588992.0000\n",
      "Epoch 186/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1838008369152.0000 - val_loss: 1663972671488.0000\n",
      "Epoch 187/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1812252459008.0000 - val_loss: 1663971622912.0000\n",
      "Epoch 188/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1858574876672.0000 - val_loss: 1663971098624.0000\n",
      "Epoch 189/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1766405264725.3333 - val_loss: 1663970181120.0000\n",
      "Epoch 190/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1868074188800.0000 - val_loss: 1663969132544.0000\n",
      "Epoch 191/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1882656604160.0000 - val_loss: 1663968477184.0000\n",
      "Epoch 192/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1792742806869.3333 - val_loss: 1663967690752.0000\n",
      "Epoch 193/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1779128991744.0000 - val_loss: 1663966773248.0000\n",
      "Epoch 194/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1830532808704.0000 - val_loss: 1663965986816.0000\n",
      "Epoch 195/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1817237083477.3333 - val_loss: 1663965331456.0000\n",
      "Epoch 196/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1805665938090.6667 - val_loss: 1663964282880.0000\n",
      "Epoch 197/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1862160657066.6667 - val_loss: 1663963496448.0000\n",
      "Epoch 198/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1815878893568.0000 - val_loss: 1663962578944.0000\n",
      "Epoch 199/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1761386845525.3333 - val_loss: 1663961792512.0000\n",
      "Epoch 200/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1760150792874.6667 - val_loss: 1663961137152.0000\n",
      "Epoch 201/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1796328150357.3333 - val_loss: 1663960219648.0000\n",
      "Epoch 202/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1810951110656.0000 - val_loss: 1663959302144.0000\n",
      "Epoch 203/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1866507266730.6667 - val_loss: 1663958646784.0000\n",
      "Epoch 204/500\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 1747227028138.6667 - val_loss: 1663957598208.0000\n",
      "Epoch 205/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1808977974613.3333 - val_loss: 1663956942848.0000\n",
      "Epoch 206/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1765933973504.0000 - val_loss: 1663956025344.0000\n",
      "Epoch 207/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1857469371733.3333 - val_loss: 1663955107840.0000\n",
      "Epoch 208/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1807824956074.6667 - val_loss: 1663954452480.0000\n",
      "Epoch 209/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1807305299285.3333 - val_loss: 1663953534976.0000\n",
      "Epoch 210/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1854349377536.0000 - val_loss: 1663953010688.0000\n",
      "Epoch 211/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1887510112938.6667 - val_loss: 1663951962112.0000\n",
      "Epoch 212/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1790842743466.6667 - val_loss: 1663950913536.0000\n",
      "Epoch 213/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1842307683669.3333 - val_loss: 1663950389248.0000\n",
      "Epoch 214/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1795036763477.3333 - val_loss: 1663949340672.0000\n",
      "Epoch 215/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1841728563882.6667 - val_loss: 1663948816384.0000\n",
      "Epoch 216/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1734741808469.3333 - val_loss: 1663947767808.0000\n",
      "Epoch 217/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1825856640341.3333 - val_loss: 1663947112448.0000\n",
      "Epoch 218/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1842594316288.0000 - val_loss: 1663946194944.0000\n",
      "Epoch 219/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1862150105770.6667 - val_loss: 1663945277440.0000\n",
      "Epoch 220/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1886812547754.6667 - val_loss: 1663944622080.0000\n",
      "Epoch 221/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1741066141696.0000 - val_loss: 1663943573504.0000\n",
      "Epoch 222/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1843556253696.0000 - val_loss: 1663942918144.0000\n",
      "Epoch 223/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1799074895189.3333 - val_loss: 1663942000640.0000\n",
      "Epoch 224/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1791311369557.3333 - val_loss: 1663941214208.0000\n",
      "Epoch 225/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1867196159317.3333 - val_loss: 1663940427776.0000\n",
      "Epoch 226/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1865214809429.3333 - val_loss: 1663939379200.0000\n",
      "Epoch 227/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1827197244757.3333 - val_loss: 1663938854912.0000\n",
      "Epoch 228/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1791071267498.6667 - val_loss: 1663937937408.0000\n",
      "Epoch 229/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1843176538112.0000 - val_loss: 1663937019904.0000\n",
      "Epoch 230/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1842856394752.0000 - val_loss: 1663936364544.0000\n",
      "Epoch 231/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1862444187648.0000 - val_loss: 1663935315968.0000\n",
      "Epoch 232/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1778081071104.0000 - val_loss: 1663934660608.0000\n",
      "Epoch 233/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1813352873984.0000 - val_loss: 1663933743104.0000\n",
      "Epoch 234/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1852975852202.6667 - val_loss: 1663932956672.0000\n",
      "Epoch 235/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1874652648789.3333 - val_loss: 1663932170240.0000\n",
      "Epoch 236/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1843193031338.6667 - val_loss: 1663931252736.0000\n",
      "Epoch 237/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1783147681109.3333 - val_loss: 1663930597376.0000\n",
      "Epoch 238/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1829497754965.3333 - val_loss: 1663929679872.0000\n",
      "Epoch 239/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1817458704384.0000 - val_loss: 1663928762368.0000\n",
      "Epoch 240/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1789098459136.0000 - val_loss: 1663927975936.0000\n",
      "Epoch 241/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1744261196458.6667 - val_loss: 1663927189504.0000\n",
      "Epoch 242/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1790350502570.6667 - val_loss: 1663926272000.0000\n",
      "Epoch 243/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1789593780224.0000 - val_loss: 1663925485568.0000\n",
      "Epoch 244/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1783050644138.6667 - val_loss: 1663924699136.0000\n",
      "Epoch 245/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1801435327146.6667 - val_loss: 1663923781632.0000\n",
      "Epoch 246/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1754680044202.6667 - val_loss: 1663922995200.0000\n",
      "Epoch 247/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1800713906858.6667 - val_loss: 1663922208768.0000\n",
      "Epoch 248/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1795946665301.3333 - val_loss: 1663921291264.0000\n",
      "Epoch 249/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1816143134720.0000 - val_loss: 1663920504832.0000\n",
      "Epoch 250/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1710933890389.3333 - val_loss: 1663919718400.0000\n",
      "Epoch 251/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1834833084416.0000 - val_loss: 1663918669824.0000\n",
      "Epoch 252/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1779243526826.6667 - val_loss: 1663918145536.0000\n",
      "Epoch 253/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1714927916373.3333 - val_loss: 1663917228032.0000\n",
      "Epoch 254/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1790078571861.3333 - val_loss: 1663916310528.0000\n",
      "Epoch 255/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1854198317056.0000 - val_loss: 1663915655168.0000\n",
      "Epoch 256/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1847230354773.3333 - val_loss: 1663914737664.0000\n",
      "Epoch 257/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1859144275285.3333 - val_loss: 1663914082304.0000\n",
      "Epoch 258/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1701002521258.6667 - val_loss: 1663913164800.0000\n",
      "Epoch 259/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1779780397738.6667 - val_loss: 1663912116224.0000\n",
      "Epoch 260/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1832648682154.6667 - val_loss: 1663911591936.0000\n",
      "Epoch 261/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1793891172352.0000 - val_loss: 1663910543360.0000\n",
      "Epoch 262/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1821700521984.0000 - val_loss: 1663910019072.0000\n",
      "Epoch 263/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1786458341376.0000 - val_loss: 1663908970496.0000\n",
      "Epoch 264/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1844057429333.3333 - val_loss: 1663908052992.0000\n",
      "Epoch 265/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 16ms/step - loss: 1736689407317.3333 - val_loss: 1663907266560.0000\n",
      "Epoch 266/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1857060973226.6667 - val_loss: 1663906480128.0000\n",
      "Epoch 267/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1815001847125.3333 - val_loss: 1663905824768.0000\n",
      "Epoch 268/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1808007233536.0000 - val_loss: 1663904776192.0000\n",
      "Epoch 269/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1804187620693.3333 - val_loss: 1663903858688.0000\n",
      "Epoch 270/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1879027482624.0000 - val_loss: 1663903203328.0000\n",
      "Epoch 271/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1760706057557.3333 - val_loss: 1663902154752.0000\n",
      "Epoch 272/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1810716426240.0000 - val_loss: 1663901630464.0000\n",
      "Epoch 273/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1831852703744.0000 - val_loss: 1663900581888.0000\n",
      "Epoch 274/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1742782311082.6667 - val_loss: 1663899664384.0000\n",
      "Epoch 275/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1832025085269.3333 - val_loss: 1663899009024.0000\n",
      "Epoch 276/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1779905986560.0000 - val_loss: 1663898222592.0000\n",
      "Epoch 277/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1829676580864.0000 - val_loss: 1663897436160.0000\n",
      "Epoch 278/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1771756475733.3333 - val_loss: 1663896518656.0000\n",
      "Epoch 279/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1790886455978.6667 - val_loss: 1663895470080.0000\n",
      "Epoch 280/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1836030732970.6667 - val_loss: 1663894814720.0000\n",
      "Epoch 281/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1745258719914.6667 - val_loss: 1663894028288.0000\n",
      "Epoch 282/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1745108795392.0000 - val_loss: 1663893241856.0000\n",
      "Epoch 283/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1855341243050.6667 - val_loss: 1663892455424.0000\n",
      "Epoch 284/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1810132784469.3333 - val_loss: 1663891668992.0000\n",
      "Epoch 285/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1763423267498.6667 - val_loss: 1663890751488.0000\n",
      "Epoch 286/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1746686618282.6667 - val_loss: 1663889833984.0000\n",
      "Epoch 287/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1747917952341.3333 - val_loss: 1663889047552.0000\n",
      "Epoch 288/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1794167122602.6667 - val_loss: 1663888261120.0000\n",
      "Epoch 289/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1848359889578.6667 - val_loss: 1663887474688.0000\n",
      "Epoch 290/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1840875503616.0000 - val_loss: 1663886688256.0000\n",
      "Epoch 291/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1772341668522.6667 - val_loss: 1663885639680.0000\n",
      "Epoch 292/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1793437444778.6667 - val_loss: 1663884984320.0000\n",
      "Epoch 293/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1838618509312.0000 - val_loss: 1663884197888.0000\n",
      "Epoch 294/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1799532249088.0000 - val_loss: 1663883411456.0000\n",
      "Epoch 295/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1782641044138.6667 - val_loss: 1663882493952.0000\n",
      "Epoch 296/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1796642897920.0000 - val_loss: 1663881707520.0000\n",
      "Epoch 297/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1803939501397.3333 - val_loss: 1663880790016.0000\n",
      "Epoch 298/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1801887372629.3333 - val_loss: 1663880003584.0000\n",
      "Epoch 299/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1805040855722.6667 - val_loss: 1663879348224.0000\n",
      "Epoch 300/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1839638358698.6667 - val_loss: 1663878430720.0000\n",
      "Epoch 301/500\n",
      "5/5 [==============================] - 0s 121ms/step - loss: 1825066582016.0000 - val_loss: 1663877382144.0000\n",
      "Epoch 302/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1797050531840.0000 - val_loss: 1663876857856.0000\n",
      "Epoch 303/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1767307258538.6667 - val_loss: 1663875940352.0000\n",
      "Epoch 304/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1856998779562.6667 - val_loss: 1663875153920.0000\n",
      "Epoch 305/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1822285845845.3333 - val_loss: 1663874236416.0000\n",
      "Epoch 306/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1713310640810.6667 - val_loss: 1663873318912.0000\n",
      "Epoch 307/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1812046457514.6667 - val_loss: 1663872663552.0000\n",
      "Epoch 308/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1827346972672.0000 - val_loss: 1663871746048.0000\n",
      "Epoch 309/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1818563138901.3333 - val_loss: 1663870959616.0000\n",
      "Epoch 310/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1830882836480.0000 - val_loss: 1663870173184.0000\n",
      "Epoch 311/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1807047939413.3333 - val_loss: 1663869255680.0000\n",
      "Epoch 312/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1805960063658.6667 - val_loss: 1663868600320.0000\n",
      "Epoch 313/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1864327473834.6667 - val_loss: 1663867551744.0000\n",
      "Epoch 314/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1834329243648.0000 - val_loss: 1663866896384.0000\n",
      "Epoch 315/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1833888601429.3333 - val_loss: 1663865978880.0000\n",
      "Epoch 316/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1831032608085.3333 - val_loss: 1663865192448.0000\n",
      "Epoch 317/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1886311372117.3333 - val_loss: 1663864406016.0000\n",
      "Epoch 318/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1832549198506.6667 - val_loss: 1663863357440.0000\n",
      "Epoch 319/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1776942252032.0000 - val_loss: 1663862833152.0000\n",
      "Epoch 320/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1855807422464.0000 - val_loss: 1663861784576.0000\n",
      "Epoch 321/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1733907425962.6667 - val_loss: 1663860867072.0000\n",
      "Epoch 322/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1846316564480.0000 - val_loss: 1663860211712.0000\n",
      "Epoch 323/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1902965642581.3333 - val_loss: 1663859163136.0000\n",
      "Epoch 324/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1864407602517.3333 - val_loss: 1663858638848.0000\n",
      "Epoch 325/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1836470610602.6667 - val_loss: 1663857590272.0000\n",
      "Epoch 326/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1864459135658.6667 - val_loss: 1663857065984.0000\n",
      "Epoch 327/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1806937292800.0000 - val_loss: 1663856148480.0000\n",
      "Epoch 328/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1781808431104.0000 - val_loss: 1663855230976.0000\n",
      "Epoch 329/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1774651528533.3333 - val_loss: 1663854444544.0000\n",
      "Epoch 330/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1836017909760.0000 - val_loss: 1663853527040.0000\n",
      "Epoch 331/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1847071910570.6667 - val_loss: 1663852740608.0000\n",
      "Epoch 332/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1762419802112.0000 - val_loss: 1663851954176.0000\n",
      "Epoch 333/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1826249484970.6667 - val_loss: 1663851036672.0000\n",
      "Epoch 334/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1840914453845.3333 - val_loss: 1663850381312.0000\n",
      "Epoch 335/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1799834086058.6667 - val_loss: 1663849332736.0000\n",
      "Epoch 336/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1757334339584.0000 - val_loss: 1663848677376.0000\n",
      "Epoch 337/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1763424731136.0000 - val_loss: 1663847890944.0000\n",
      "Epoch 338/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1828169165482.6667 - val_loss: 1663846842368.0000\n",
      "Epoch 339/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1888455469738.6667 - val_loss: 1663846187008.0000\n",
      "Epoch 340/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1751417836885.3333 - val_loss: 1663845138432.0000\n",
      "Epoch 341/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1825638296234.6667 - val_loss: 1663844483072.0000\n",
      "Epoch 342/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1869762483541.3333 - val_loss: 1663843696640.0000\n",
      "Epoch 343/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1846225076224.0000 - val_loss: 1663842648064.0000\n",
      "Epoch 344/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1880759642794.6667 - val_loss: 1663841992704.0000\n",
      "Epoch 345/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1773647626240.0000 - val_loss: 1663841075200.0000\n",
      "Epoch 346/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1773182757546.6667 - val_loss: 1663840288768.0000\n",
      "Epoch 347/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1810949581482.6667 - val_loss: 1663839633408.0000\n",
      "Epoch 348/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1849474722474.6667 - val_loss: 1663838584832.0000\n",
      "Epoch 349/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1787895829845.3333 - val_loss: 1663837929472.0000\n",
      "Epoch 350/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1843786787498.6667 - val_loss: 1663836880896.0000\n",
      "Epoch 351/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1845574303744.0000 - val_loss: 1663836225536.0000\n",
      "Epoch 352/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1808605926741.3333 - val_loss: 1663835439104.0000\n",
      "Epoch 353/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1801297701546.6667 - val_loss: 1663834521600.0000\n",
      "Epoch 354/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1754835080533.3333 - val_loss: 1663833866240.0000\n",
      "Epoch 355/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1845215275690.6667 - val_loss: 1663832948736.0000\n",
      "Epoch 356/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1859123369301.3333 - val_loss: 1663832162304.0000\n",
      "Epoch 357/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1786763520682.6667 - val_loss: 1663831375872.0000\n",
      "Epoch 358/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1801914460842.6667 - val_loss: 1663830720512.0000\n",
      "Epoch 359/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1892218481322.6667 - val_loss: 1663829671936.0000\n",
      "Epoch 360/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1789376353621.3333 - val_loss: 1663828623360.0000\n",
      "Epoch 361/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1825050416469.3333 - val_loss: 1663827968000.0000\n",
      "Epoch 362/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1797915257514.6667 - val_loss: 1663827181568.0000\n",
      "Epoch 363/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1859537229141.3333 - val_loss: 1663826132992.0000\n",
      "Epoch 364/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1835287358122.6667 - val_loss: 1663825477632.0000\n",
      "Epoch 365/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1817823150080.0000 - val_loss: 1663824560128.0000\n",
      "Epoch 366/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1795350855680.0000 - val_loss: 1663823904768.0000\n",
      "Epoch 367/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1822596311722.6667 - val_loss: 1663822987264.0000\n",
      "Epoch 368/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1795075757397.3333 - val_loss: 1663821938688.0000\n",
      "Epoch 369/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1825709249877.3333 - val_loss: 1663821414400.0000\n",
      "Epoch 370/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1853690194602.6667 - val_loss: 1663820365824.0000\n",
      "Epoch 371/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1829917097984.0000 - val_loss: 1663819841536.0000\n",
      "Epoch 372/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1893221400576.0000 - val_loss: 1663818792960.0000\n",
      "Epoch 373/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1854794803882.6667 - val_loss: 1663818268672.0000\n",
      "Epoch 374/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1839454115157.3333 - val_loss: 1663817220096.0000\n",
      "Epoch 375/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1808265554602.6667 - val_loss: 1663816433664.0000\n",
      "Epoch 376/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1832341296469.3333 - val_loss: 1663815647232.0000\n",
      "Epoch 377/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1806791584426.6667 - val_loss: 1663814729728.0000\n",
      "Epoch 378/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1821578057045.3333 - val_loss: 1663814074368.0000\n",
      "Epoch 379/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1811282154837.3333 - val_loss: 1663813025792.0000\n",
      "Epoch 380/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1794413406890.6667 - val_loss: 1663812239360.0000\n",
      "Epoch 381/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1831980608170.6667 - val_loss: 1663811584000.0000\n",
      "Epoch 382/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1854155281749.3333 - val_loss: 1663810535424.0000\n",
      "Epoch 383/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1772730733909.3333 - val_loss: 1663809880064.0000\n",
      "Epoch 384/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1801258642090.6667 - val_loss: 1663808831488.0000\n",
      "Epoch 385/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1808946211498.6667 - val_loss: 1663808045056.0000\n",
      "Epoch 386/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1760976917845.3333 - val_loss: 1663807389696.0000\n",
      "Epoch 387/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1876625784832.0000 - val_loss: 1663806603264.0000\n",
      "Epoch 388/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1763839333717.3333 - val_loss: 1663805685760.0000\n",
      "Epoch 389/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1865093218304.0000 - val_loss: 1663804768256.0000\n",
      "Epoch 390/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1852989221546.6667 - val_loss: 1663803719680.0000\n",
      "Epoch 391/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1767138634410.6667 - val_loss: 1663803195392.0000\n",
      "Epoch 392/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1893938954240.0000 - val_loss: 1663802146816.0000\n",
      "Epoch 393/500\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 1825041438037.3333 - val_loss: 1663801622528.0000\n",
      "Epoch 394/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1795821666304.0000 - val_loss: 1663800705024.0000\n",
      "Epoch 395/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1774205687125.3333 - val_loss: 1663799787520.0000\n",
      "Epoch 396/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1808379565397.3333 - val_loss: 1663799001088.0000\n",
      "Epoch 397/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 16ms/step - loss: 1747519777450.6667 - val_loss: 1663798214656.0000\n",
      "Epoch 398/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1853768947029.3333 - val_loss: 1663797428224.0000\n",
      "Epoch 399/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1807547716949.3333 - val_loss: 1663796510720.0000\n",
      "Epoch 400/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1762561993386.6667 - val_loss: 1663795593216.0000\n",
      "Epoch 401/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1779141225130.6667 - val_loss: 1663795068928.0000\n",
      "Epoch 402/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1815511979349.3333 - val_loss: 1663794020352.0000\n",
      "Epoch 403/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1868957308245.3333 - val_loss: 1663793364992.0000\n",
      "Epoch 404/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1830457202005.3333 - val_loss: 1663792447488.0000\n",
      "Epoch 405/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1800866540202.6667 - val_loss: 1663791529984.0000\n",
      "Epoch 406/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1780253895338.6667 - val_loss: 1663790874624.0000\n",
      "Epoch 407/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1779349782528.0000 - val_loss: 1663789826048.0000\n",
      "Epoch 408/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1864471915178.6667 - val_loss: 1663789170688.0000\n",
      "Epoch 409/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1844378118826.6667 - val_loss: 1663788384256.0000\n",
      "Epoch 410/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1768415712597.3333 - val_loss: 1663787597824.0000\n",
      "Epoch 411/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1765059766954.6667 - val_loss: 1663786811392.0000\n",
      "Epoch 412/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1775169918293.3333 - val_loss: 1663785762816.0000\n",
      "Epoch 413/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1826540814336.0000 - val_loss: 1663785107456.0000\n",
      "Epoch 414/500\n",
      "5/5 [==============================] - 0s 116ms/step - loss: 1884761139882.6667 - val_loss: 1663784058880.0000\n",
      "Epoch 415/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1840200286208.0000 - val_loss: 1663783403520.0000\n",
      "Epoch 416/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1828540841984.0000 - val_loss: 1663782617088.0000\n",
      "Epoch 417/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1807470056789.3333 - val_loss: 1663781568512.0000\n",
      "Epoch 418/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1903400495786.6667 - val_loss: 1663781044224.0000\n",
      "Epoch 419/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1820655856298.6667 - val_loss: 1663779995648.0000\n",
      "Epoch 420/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1857326394026.6667 - val_loss: 1663779340288.0000\n",
      "Epoch 421/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1792093585408.0000 - val_loss: 1663778422784.0000\n",
      "Epoch 422/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1774600716288.0000 - val_loss: 1663777505280.0000\n",
      "Epoch 423/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1831188256085.3333 - val_loss: 1663776849920.0000\n",
      "Epoch 424/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1845042173269.3333 - val_loss: 1663775801344.0000\n",
      "Epoch 425/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1833063809024.0000 - val_loss: 1663775145984.0000\n",
      "Epoch 426/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1850695811072.0000 - val_loss: 1663774228480.0000\n",
      "Epoch 427/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1764342147754.6667 - val_loss: 1663773310976.0000\n",
      "Epoch 428/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1784762619221.3333 - val_loss: 1663772655616.0000\n",
      "Epoch 429/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1806789858645.3333 - val_loss: 1663771738112.0000\n",
      "Epoch 430/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1804668480170.6667 - val_loss: 1663771082752.0000\n",
      "Epoch 431/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1809964007424.0000 - val_loss: 1663770034176.0000\n",
      "Epoch 432/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1791980754261.3333 - val_loss: 1663768985600.0000\n",
      "Epoch 433/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1839957540864.0000 - val_loss: 1663768461312.0000\n",
      "Epoch 434/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1850753155072.0000 - val_loss: 1663767543808.0000\n",
      "Epoch 435/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1805612373333.3333 - val_loss: 1663766888448.0000\n",
      "Epoch 436/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1792405471232.0000 - val_loss: 1663765970944.0000\n",
      "Epoch 437/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1836792720042.6667 - val_loss: 1663764922368.0000\n",
      "Epoch 438/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1860471750656.0000 - val_loss: 1663764398080.0000\n",
      "Epoch 439/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1906607783936.0000 - val_loss: 1663763349504.0000\n",
      "Epoch 440/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1774794003797.3333 - val_loss: 1663762694144.0000\n",
      "Epoch 441/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1802295050240.0000 - val_loss: 1663761907712.0000\n",
      "Epoch 442/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1821669785600.0000 - val_loss: 1663760990208.0000\n",
      "Epoch 443/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1761042519381.3333 - val_loss: 1663760203776.0000\n",
      "Epoch 444/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1828838528341.3333 - val_loss: 1663759286272.0000\n",
      "Epoch 445/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1858564784128.0000 - val_loss: 1663758499840.0000\n",
      "Epoch 446/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1758282186752.0000 - val_loss: 1663757713408.0000\n",
      "Epoch 447/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1834045385386.6667 - val_loss: 1663756795904.0000\n",
      "Epoch 448/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1885096924501.3333 - val_loss: 1663756140544.0000\n",
      "Epoch 449/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1803150142122.6667 - val_loss: 1663755354112.0000\n",
      "Epoch 450/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1820943537493.3333 - val_loss: 1663754305536.0000\n",
      "Epoch 451/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1854117205333.3333 - val_loss: 1663753519104.0000\n",
      "Epoch 452/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1820167329109.3333 - val_loss: 1663752732672.0000\n",
      "Epoch 453/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1790723315029.3333 - val_loss: 1663752077312.0000\n",
      "Epoch 454/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1879934610090.6667 - val_loss: 1663751028736.0000\n",
      "Epoch 455/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1892745368917.3333 - val_loss: 1663750242304.0000\n",
      "Epoch 456/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1840160003413.3333 - val_loss: 1663749586944.0000\n",
      "Epoch 457/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1861144434005.3333 - val_loss: 1663748669440.0000\n",
      "Epoch 458/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1789074538496.0000 - val_loss: 1663747883008.0000\n",
      "Epoch 459/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1843705544704.0000 - val_loss: 1663746834432.0000\n",
      "Epoch 460/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1795952869376.0000 - val_loss: 1663746179072.0000\n",
      "Epoch 461/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1774036669781.3333 - val_loss: 1663745261568.0000\n",
      "Epoch 462/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1751839604736.0000 - val_loss: 1663744344064.0000\n",
      "Epoch 463/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1790924226560.0000 - val_loss: 1663743688704.0000\n",
      "Epoch 464/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1847840320170.6667 - val_loss: 1663742771200.0000\n",
      "Epoch 465/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1831890124800.0000 - val_loss: 1663742115840.0000\n",
      "Epoch 466/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1724193002837.3333 - val_loss: 1663741198336.0000\n",
      "Epoch 467/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1833993568256.0000 - val_loss: 1663740542976.0000\n",
      "Epoch 468/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1920655840597.3333 - val_loss: 1663739625472.0000\n",
      "Epoch 469/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1889374349994.6667 - val_loss: 1663738576896.0000\n",
      "Epoch 470/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1846166639957.3333 - val_loss: 1663737921536.0000\n",
      "Epoch 471/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1873175489194.6667 - val_loss: 1663737004032.0000\n",
      "Epoch 472/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1864778667349.3333 - val_loss: 1663736348672.0000\n",
      "Epoch 473/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1754258254506.6667 - val_loss: 1663735431168.0000\n",
      "Epoch 474/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1724905248085.3333 - val_loss: 1663734382592.0000\n",
      "Epoch 475/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1784364903082.6667 - val_loss: 1663733858304.0000\n",
      "Epoch 476/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1913711667882.6667 - val_loss: 1663732809728.0000\n",
      "Epoch 477/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1747007067477.3333 - val_loss: 1663732285440.0000\n",
      "Epoch 478/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1834310500352.0000 - val_loss: 1663731236864.0000\n",
      "Epoch 479/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1896204271616.0000 - val_loss: 1663730450432.0000\n",
      "Epoch 480/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1878817985877.3333 - val_loss: 1663729664000.0000\n",
      "Epoch 481/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1861606659413.3333 - val_loss: 1663728615424.0000\n",
      "Epoch 482/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1870537577813.3333 - val_loss: 1663728091136.0000\n",
      "Epoch 483/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1776658481152.0000 - val_loss: 1663727042560.0000\n",
      "Epoch 484/500\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 1834976761173.3333 - val_loss: 1663726125056.0000\n",
      "Epoch 485/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1777378721792.0000 - val_loss: 1663725600768.0000\n",
      "Epoch 486/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1869148192768.0000 - val_loss: 1663724552192.0000\n",
      "Epoch 487/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1785519385258.6667 - val_loss: 1663723896832.0000\n",
      "Epoch 488/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1805751637333.3333 - val_loss: 1663722979328.0000\n",
      "Epoch 489/500\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 1835945470634.6667 - val_loss: 1663721930752.0000\n",
      "Epoch 490/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1792610620757.3333 - val_loss: 1663721406464.0000\n",
      "Epoch 491/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1841747853312.0000 - val_loss: 1663720488960.0000\n",
      "Epoch 492/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1766311133184.0000 - val_loss: 1663719833600.0000\n",
      "Epoch 493/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1838273724416.0000 - val_loss: 1663718785024.0000\n",
      "Epoch 494/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1779602598570.6667 - val_loss: 1663717998592.0000\n",
      "Epoch 495/500\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 1872775675904.0000 - val_loss: 1663717212160.0000\n",
      "Epoch 496/500\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 1819966024362.6667 - val_loss: 1663716294656.0000\n",
      "Epoch 497/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1833334996992.0000 - val_loss: 1663715508224.0000\n",
      "Epoch 498/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1818267877376.0000 - val_loss: 1663714721792.0000\n",
      "Epoch 499/500\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 1806367850496.0000 - val_loss: 1663713804288.0000\n",
      "Epoch 500/500\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 1800165720064.0000 - val_loss: 1663713280000.0000\n"
     ]
    }
   ],
   "source": [
    "# 의외로 데이터가 적어... 정확도가 안 올라가면 맨토님에게 상담해야지 뭔가 한번 반복할때마다 저 값들이 바뀐다던가... 흠... 일단 가자..\n",
    "\n",
    "history=model.fit(x_train, y_train,\n",
    "         validation_data=(x_test, y_test),\n",
    "         batch_size=10,\n",
    "         epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a5fd36d588>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history #???? 왜 이미 값 이 있지????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAERCAYAAABhKjCtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xU5bX/8c+CBEJIBDEYrPQ0VC0VLERIQeotqRWxoiJoMYoVvHB59aeolVOwtnrq6WmteKGnrZRfpeivSLQotUUrUEukWioCRYxG6w01oiWCQILcEtbvj70DAXfCMGQySeb7fr3mxZ5nP8+etZIwa/Zlnm3ujoiIyIHaJTsAERFpmVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCK1uQJhZrPNbIOZlcXQ9wwzW21mNWZ2cb32fDNbbmavmNlaMxud2KhFRFqeNlcggDnAsBj7vgeMBR4+oP1T4Nvu3jfc1n1m1rWpAhQRaQ3Skh1AU3P3ZWaWV7/NzI4Dfgl0J3jzv9bdX3P3deH6PQds41/1lteb2YZw7OaEBi8i0oK0uQLRgFnARHd/w8wGA78Cvh7LQDMbBHQA3kpgfCIiLU6bLxBmlgV8Dfi9mdU1d4xx7DHA/wOudPc9B+svItKWtPkCQXCeZbO75x/KIDM7AngSuNXd/5GQyEREWrC2eJJ6P+6+FXjHzC4BsED/xsaYWQdgAfCQu/++GcIUEWlxElYgDna5qZl1MbM/mdlL4eWk48L2w7rE1MzmAcuB3mZWYWZXA5cDV5vZS8ArwIVh36+aWQVwCfBrM3sl3My3gDOAsWa2Jnwc0h6IiEhrZ4ma7tvMzgCqCT6FnxSx/hagi7t/z8y6A68DPYA8wMMTyp8DVgEnuruuIBIRaUYJOwcRdbnpgV2AbAvOHGcBm4AaXWIqItIyJPMk9S+APwLrgWxg9IFXCh3qJaY5OTmel5cXVzDbtm2jc+fOcY1trZRzalDOqSHenFetWvWxu3ePWpfMAnEOsIbg+wjHAUvM7G/hSeWYLzE1s/HAeIDc3FymT58eVzDV1dVkZWXFNba1Us6pQTmnhnhzLioqerfBle6esAfB+YSyBtY9CZxe7/lfgUHh8hHAauCSQ3m9gQMHeryWLl0a99jWSjmnBuWcGuLNGVjpDbynJvMy1/eAswDMLBfoDbytS0xFRFqGhB1iCi83LQRywktJbwPSAdx9JnAHMMfMXgYM+J67f2xmYwguMT3KzMaGmxvr7msSFauIiHxWIq9iKj7I+vXA0Ij23wG/S1RcIqlo9+7dVFRUsGPHjmSH0iy6dOlCeXl5ssNoVgfLOSMjg549e5Kenh7zNlNhqg2RlFdRUUF2djZ5eXnUm5OszaqqqiI7OzvZYTSrxnJ2dzZu3EhFRQW9evWKeZttfqoNEYEdO3Zw1FFHpURxkM8yM4466qhD3oPUHgQwaxbce+8AMjLgk0/ADLp2hZ07oWPH/dtiWT6Uccl8jZ07B9GjR/Pn0Zw5d+gAV18N48cn+68s+VQcUls8v/+ULxCzZsGECRB8Vy/VdOKjj5IdQ+KtWAHf/z6kpcHOnUPo1g22bQvWZWVBdXWwnJ0Nu3dDejpUVe1rO3DZLBhXUxNss/74hsbV9Yl1nFmwvGtXUOS2bt3XVn+5btwRR+zft65t61bYuXMwJSXr2LUraG/fHmprg220awfuwfKe8NtG7dpFL7dvv69vbe3+2zrY8qGMa4q+7pmkpe1rT0sLfu51y3v2BLnVb2to+VD6Jus1gr/JdJr6qFrKF4jHHqtbSsVPV6mT88cf1y115JNPovtEFcv6bQcrph9+ePDlRPngg8baOrF7d1D8YN+/zWnChELGjp3GkCHn7G17+OH7eO+9fzF16q8aHHfGGVksW1ZNZeV6pk+/njvvnB+57cmTp9OnT0G91vb75Tlnzn2MHDmejIxMdu2CyZO/yX//98NkZwd3Eq4rno0tH2x9LOP+9Kc5nHLKULp3/9xn+t5++1hOP304Z511cVyvsW1bRzIyoHvkd6Ljk/LnIEaNqltKzKSFLVsq5izJcM45xSxeXLJf25IlJZxzTqMXO+7VvfvnIotDrEpK7mPHjk/3Pp8x46m9xaE5LVw4h8rK9QnbfkMffuKV8nsQdcem7723ioyMI1rM+YHmOQexnR49MtvsOYiqKqioOPA37qTSnlMgvg8CndcuJ3tVKVUDC9nWb8hhRfD1r1/M/fffyq5dO+nQoSPr16+jsnI9+fmn8emn1Xz3uxdSVfUJNTW7mTTpvznzzAv3G79+/TpuvHE4jzxSxo4d2/nRj8bxzjuvkpd3Ijt3bt/b76c/ncSrr77Ijh3bOeusi5kw4b8oKfk5lZXrmTixiK5dc5g5cykXXJDHQw+tpGvXHObOvYc//nE2ABdeeA2XXXYD69evY/Lkc+nf/zTWrv07Rx99LNOnP0FGRqf94tq+fRvTpn2LDRsqqK2t5eqrf8DQoaMpL1/FvffexPbt1XTtmsNtt83hpZeep7x8JT/4weV07NiJ2bOXf2Z7B3J3fv7z/+Tvf/8zZsZVV93K0KGj+fjjD7nlltFUV2+ltraGqVPvp1+/Ifzwh9dQVrYy7HsVN95442H93lK+QEBQJL70pdUUFhYmO5RmVVq6os3nPGsWPPBAsDuezKKYzMK7c+d2OnQIzk8AHHvXDXR8LfjeqRl7a2bdzP9mYFVb6PT6WvA9YO3Y3rsfnt0lsq87bO+dT+Ut9zV4rDwj4yj69RvEiy8+TVHRhSxdWsKwYaPp2NHo2DGDGTMWkJV1BFVVH1NcfArDhl1AbW1QyDMzg/NCZsFyScn9ZGZm8sQTaykvX8vo0QNITw/yu+mmH5OV1Y2aml1MnDiUdevW8u1vX8+8effwwANLOfLIHNLSgm116gRvvrmKhQt/yyOPvEBNjXP55YM59dQzycw8kvfff4Pp0+fRu/f/5eabv8WyZY8xfPiY/XJ77rmnyc39HL/61ZOkpcEnn2zBbDf33HMdM2Y8QU5OdxYufISZM7/P//zPbObP/wU33TSd/v0LPnMuIS0teHTosO/n95e/PM5bb61h/vyX2Lz5Yy677KsMHnwGS5Y8zOmnn8O1134f91p27vyUf/97BRs3fkBZWXALns2bD38CbBUIadPGj9//CqZUKIoHKi1dQW5uLieeGDYcBRxs0s+PtwTFAcD3kLlzC+R2abB7Vg5079P4Jq+9tpgnnyxh8uSgQMyePZt+/WD3bufGG29h2bJltGvXjsrKDzjqqH/To0cP2rWDPn2CwpCRESy/+eYyrr/+evr0gT59+tGvXz9OOAH69YOZMx9l1qxZ7Nq1i3//+9/U1LxKv379SE+Hvn0hJyeIJT0deveGlSufo7j4IgoKgh/IZZeN5IMP/sYFF1xAr169GDUquE9YUdFAdu9eR79+++eUkfEVZsy4mblzv8fw4cM5/fTTKSsr4623yrj++rMBqK2t5ZhjjqFPH+jcGU44IcjjQF27whe+wH6v8dvfPsc11xRz8sntgVy+8Y0z2bbtRS688KtcddVVHHnkbkaMGEFBQT7vvdeTt99+m+uuu47zzjuPoUM/8z3kQ6YCIZJq7rvv4H2WL4ezztp3adTcuTDk8A4zjRgxgptuuonVq1ezfft2BgwYAMDcuXOprKxk1apVpKenk5eXd9Dr9aMu2XznnXeYPn06L774ImlpaVx33XUH3Y43csO0jh077l1u374927dv5/333+f8888HYOLEiUycOJFVq1bx1FNPMW3aNIYOHcpFF11E3759Wb58eaOvHYuG4jvjjDNYtmwZTz75JFdccQVTpkzhoosu4qWXXmLRokX88pe/5NFHH2X27NmH9fopf5JaRCIMGQLPPAN33BH8e5jFASArK4vCwkKuuuoqiov3nZzesmULRx99NOnp6SxdupR332149mkI3hznzp0LQFlZGWvXrgVg69atdO7cmS5durBhwwb+/Oc/7x2TnZ1NVd01wQds6w9/+AOffvop27ZtY8GCBZx++ukNvvbnP/951qxZw5o1a5g4cSLr168nMzOTMWPGcPPNN7N69Wp69+5NZWXl3gKxe/duXnnllUbjaCzXRx55hNraWiorK1m2bBmDBg3i3Xff5eijj+baa6/l6quvZvXq1WzcuJE9e/YwatQo7rjjDlavXh3z6zREexAiEm3IkCYpDPUVFxczcuRISkr2XdF0+eWXc/7551NQUEB+fj5f/vKXG93GpEmTGDduHP369SM/P59BgwYB0L9/f04++WT69u3Lf/zHf3DqqafuHTN+/HjOPfdcjjnmGJYuXbq3fcCAAYwdO3bvNq655hpOPvlk1q1bF1M+L7/8MlOmTKFdu3akp6dz//3306FDB+bPn8/111/Pli1bqKmp4YYbbqBv376MHTuWiRMn0qlTJ5YvX06nTvufpJ4wYQI33HADEBSjv//97yxfvpz+/ftjZvzsZz+jR48ePPjgg9x1112kp6eTlZXFQw89xPr16xk5ciR7wi+u/OQnP4kph8Yk7J7UyVBQUOArV66Ma2xpaWkKHptWzqmgtLQ0PAdx4sE7txGaiylaeXn5Z/4OzGyVuxdE9dchJhERiaQCISIikVQgREQkkgqEiIhEUoEQEZFICS0QZjbbzDaYWVkD67uY2Z/M7CUze8XMxtVbd6WZvRE+rkxknCIi8lmJ3oOYAwxrZP13gFfdvT9QCNxtZh3MrBtwGzAYGATcZmZHJjhWEUmQjRs3kp+fT35+Pj169ODYY4/d+3xX1NzYEcaNG8frr7+esBgff/xxXnvttch1t956K/fF8g30NiahX5Rz92VmltdYFyDbgu/NZwGbgBrgHGCJu28CMLMlBIVmXiLjFZHEOOqoo1izJpgg8PbbbycrK4ubb755vz7ujrvTrl3059bf/va3CY3x8ccfp127dgf9ol4qSfY3qX8B/BFYT3BLt9HuvsfMjgXer9evAjg2agNmNh4YD5Cbm0tpaWlcgVRXV8c9trVSzqmhurqaLl26HNIUDwAvvNCO555L47TTahg8eE+TxbNz507S09Opqqrirbfe4rLLLmPIkCGsXLmSRx99lJ/+9Ke89NJLbN++nZEjRzJ16lQAhg4dyvTp0+nTpw+9evXiqquuYsmSJXTq1ImSkhK617tTTm1tLZ988gmTJk3i5Zdfxt0ZO3YskyZN4s033+Tmm29m06ZNZGZm8r//+79UVlby5JNP8txzz/HDH/6Qhx9+mC984Qv7xbxjx47P/Azvu+8+5s0LPreOGzeOiRMnUlVVxZVXXslHH31EbW0t06ZNY8SIEdx6660sWrSItLQ0zj77bH70ox812c+0LueD/Y537NhxSH//yS4Q5wBrgK8DxwFLzOxvRE/YH/mVb3efBcyC4JvU8X5LNlW/Yauc277S0lIyMjL2fsv2hhsg/DDfoC1bYO3aultadqRfP+jS8GSu5OfHNgcgBJPgdezYkezsbLKysnjttdd48MEH+epXvwrA3XffTbdu3aipqaGoqIjLL7+cPn360L59ezp37kx2djZbtmzh7LPP5p577uGmm27i0Ucf3VtIIPhW8auvvsqWLVv2zoO0efNmsrOzuemmm/jNb37Dcccdx/PPP8/UqVNZvHgx5513HhdffDEjRoyIjLn+zxBgxYoVzJ8/n5UrV1JbW8ugQYM455xzKC8v5/jjj2fJkiXhz3ILn376KX/5y18oLy/HzPbG0pRi+SZ1RkYGJ598cszbTPZVTOOAxz3wJvAO8GWCPYbP1+vXk2AvQ0SawZYt++5FvWdP8DxRjjvuuL3FAWDevHkMGDCAAQMGUF5ezquvvvqZMZ06deLcc88FYODAgZFzJx1//PG8/vrrTJ48mUWLFtGlSxc2b97MP/7xD0aNGkV+fj7f+c53WL8+vreWv/3tb4waNYrMzEyys7MZMWIEzz33HP369ePpp59m6tSpPP/883Tp0oVu3brRrl07rr32WhYsWEDnzgebb71lSPYexHvAWcDfzCwX6A28DbwJ/E+9E9NDgWnJCVGkbUnSbN8Nqv9m+cYbbzBjxgxWrFhB165dGTNmTOSU3R3q7n5EMBV3TU0Nu3bt2jvp3nnnncePf/xj1q5dy5///Gd+/vOf89hjj3HnnXeSk5Oz93zI4WhoHrsTTzyRlStX8tRTTzFlyhSGDx/OLbfcwsqVK1myZAklJSXcf//9LF68+LBjSLSEFggzm0dwdVKOmVUQXJmUDuDuM4E7gDlm9jLBYaXvufvH4dg7gBfDTf2o7oS1iCRe3WzfpaVQWJi44nCgrVu3kp2dzRFHHMGHH37IokWLGDassQsh9+nQocPeN/6qqioqKyvJyMjgkksuoVevXkycOJEjjzySY445hgULFnDRRRexZ88eXn75Zfr37x/XVNwTJkxgypQp1NbW8sQTT/DII4/wwQcfkJOTwxVXXLH3/EhVVRU7duxg+PDhDB48mD5RdwxqgRJ9FVOjdyR39/UEewdR62YDh3e3CxGJWwJm+z6oAQMG0KdPH0466SS++MUv7jdl96F6//33ufrqq3F3zIw777wTgJKSEiZNmsTtt9/Orl27GDNmDP3796e4uJgJEyZw991384c//IG8vLz9tnf77bczffp0ANLS0li3bh3FxcV7D49NmjSJr3zlKzz11FNMnTqVdu3a0aFDB2bOnMmWLVsYOXIkO3fuZM+ePdxzzz1x59WcNN13KFVPXirntk/TfacGTfctIiLNRgVCREQiqUCIpIi2dDhZDl08v38VCJEUkJGRwcaNG1UkUpS7s3HjRjIyMg5pXLK/ByEizaBnz55UVFRQWVmZ7FCaxY4dOw75zbC1O1jOGRkZ9OzZ85C2qQIhkgLS09Pp1atXssNoNqWlpYc0pURbkIicdYhJREQiqUCIiEgkFQgREYmkAiEiIpFUIEREJJIKhIiIRFKBEBGRSCoQIiISSQVCREQiqUCIiEikhBUIM5ttZhvMrKyB9VPMbE34KDOzWjPrFq670cxeCdvnmVlqTaoiItICJHIPYg7Q4M1k3f0ud89393xgGvCsu28ys2OB64ECdz8JaA9cmsA4RUQkQsIKhLsvAzbF2L0YmFfveRrQyczSgExgfROHJyIiB5H0cxBmlkmwp/EYgLt/AEwH3gM+BLa4++LkRSgikposkTcQMbM8YGF4qKihPqOBMe5+fvj8SIJiMRrYDPwemO/uv2tg/HhgPEBubu7AkpKSuGKtrq4mKysrrrGtlXJODco5NcSbc1FR0Sp3L4ha1xLuB3Ep+x9e+gbwjrtXApjZ48DXgMgC4e6zgFkABQUFXlhYGFcQpaWlxDu2tVLOqUE5p4ZE5JzUQ0xm1gU4E3iiXvN7wClmlmlmBpwFlCcjPhGRVJawPQgzmwcUAjlmVgHcBqQDuPvMsNtFwGJ331Y3zt1fMLP5wGqgBvgn4R6CiIg0n4QVCHcvjqHPHILLYQ9sv42goIiISJIk/SomERFpmVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkUsIKhJnNNrMNZlbWwPopZrYmfJSZWa2ZdQvXdTWz+Wb2mpmVm9mQRMUpIiLRErkHMQcY1tBKd7/L3fPdPR+YBjzr7pvC1TOAp939y0B/oDyBcYqISISEFQh3XwZsOmjHQDEwD8DMjgDOAB4It7PL3TcnJEgREWmQuXviNm6WByx095Ma6ZMJVADHu/smM8sHZgGvEuw9rAImu/u2BsaPB8YD5ObmDiwpKYkr1urqarKysuIa21op59SgnFNDvDkXFRWtcveCyJXunrAHkAeUHaTPaOBP9Z4XADXA4PD5DOCOWF5v4MCBHq+lS5fGPba1Us6pQTmnhnhzBlZ6A++pLeEqpksJDy+FKoAKd38hfD4fGNDsUYmIpLikFggz6wKcCTxR1+buHwHvm1nvsOksgsNNIiLSjNIStWEzmwcUAjlmVgHcBqQDuPvMsNtFwGL/7PmF64C5ZtYBeBsYl6g4RUQkWsIKhLsXx9BnDsHlsAe2ryE4FyEiIknSEs5BiIhIC6QCISIikVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiRRTgTCzyWZ2hAUeMLPVZjY00cGJiEjyxLoHcZW7bwWGAt0J7hH908YGmNlsM9tgZmUNrJ9iZmvCR5mZ1ZpZt3rr25vZP81sYYwxiohIE4q1QFj47zeB37r7S/XaGjIHGNbQSne/y93z3T0fmAY86+6b6nWZDJTHGJ+IiDSxWAvEKjNbTFAgFplZNrCnsQHuvgzY1FifeoqBeXVPzKwncB7wmxjHi4hIEzN3P3gns3ZAPvC2u28ODwX1dPe1BxmXByx095Ma6ZMJVADH1+1BmNl84CdANnCzuw9vZPx4YDxAbm7uwJKSkoPmE6W6upqsrKy4xrZWyjk1KOfUEG/ORUVFq9y9IGpdWozbGAKscfdtZjYGGADMOORIop0PPF+vOAwHNrj7KjMrPNhgd58FzAIoKCjwwsKDDolUWlpKvGNbK+WcGpRzakhEzrEeYrof+NTM+gP/CbwLPNREMVxKvcNLwKnABWa2DigBvm5mv2ui1xIRkRjFWiBqPDgWdSEww91nEBz+OSxm1gU4E3iirs3dp7l7T3fPIygef3X3MYf7WiIicmhiPcRUZWbTgCuA082sPZDe2AAzmwcUAjlmVgHcVjfG3WeG3S4CFrv7tjhiFxGRBIq1QIwGLiP4PsRHZvYfwF2NDXD34oNt1N3nEFwO29D6UqA0xhhFRKQJxXSIyd0/AuYCXcKTyDvcvanOQYiISAsU61Qb3wJWAJcA3wJeMLOLExmYiIgkV6yHmL4PfNXdNwCYWXfgL8D8RAUmIiLJFetVTO3qikNo4yGMFRGRVijWPYinzWwR+76vMBp4KjEhiYhISxBTgXD3KWY2iuBLbAbMcvcFCY1MRESSKtY9CNz9MeCxBMYiIiItSKMFwsyqgKjZ/Axwdz8iIVGJiEjSNVog3P2wp9MQEZHWSVciiYhIJBUIERGJpAIhIiKRVCBERCSSCoSIiERSgRARkUgqECIiEkkFQkREIiWsQJjZbDPbYGZlDayfYmZrwkeZmdWaWTcz+7yZLTWzcjN7xcwmJypGERFpWCL3IOYAwxpa6e53uXu+u+cD04Bn3X0TUAN8191PBE4BvmNmfRIYp4iIREhYgXD3ZcCmGLsXE04l7u4fuvvqcLkKKAeOTUiQIiLSIHOPmouviTZulgcsdPeTGumTCVQAx4d7EAeOXwac5O5bGxg/HhgPkJubO7CkpCSuWKurq8nKyoprbGulnFODck4N8eZcVFS0yt0LIle6e8IeQB5QdpA+o4E/RbRnAauAkbG+3sCBAz1eS5cujXtsa6WcU4NyTg3x5gys9AbeU1vCVUyXsu9OdQCYWTrBvSfmuvvjSYlKRCTFJbVAmFkX4EzgiXptBjwAlLv7PcmKTUQk1cV8R7lDZWbzgEIgx8wqgNuAdAB3nxl2uwhY7O7b6g09FbgCeNnM1oRtt7i77oEtItKMElYg3L04hj5zCC6Hrd/2HMEd60REJIlawjkIERFpgVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkUsIKhJnNNrMNZlbWwPopZrYmfJSZWa2ZdQvXDTOz183sTTObmqgYRUSkYYncg5gDDGtopbvf5e757p4PTAOedfdNZtYe+CVwLtAHKDazPgmMU0REIiSsQLj7MmBTjN2LgXnh8iDgTXd/2913ASXAhQkIUUREGmHunriNm+UBC939pEb6ZAIVwPHhHsTFwDB3vyZcfwUw2N3/TwPjxwPjAXJzcweWlJTEFWt1dTVZWVlxjW2tlHNqUM6pId6ci4qKVrl7QdS6tMOO6vCdDzzv7nV7GxbRp8Eq5u6zgFkABQUFXlhYGFcQpaWlxDu2tVLOqUE5p4ZE5NwSrmK6lH2HlyDYm/h8vec9gfXNGpGIiCS3QJhZF+BM4Il6zS8CJ5hZLzPrQFBA/piM+EREUlnCDjGZ2TygEMgxswrgNiAdwN1nht0uAha7+7a6ce5eY2b/B1gEtAdmu/sriYpTRESiJaxAuHtxDH3mEFwOe2D7U8BTTR+ViIjEqiWcgxARkRZIBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkkgqEiIhEUoEQEZFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkkgqEiIhEUoEQEZFIKhAiIhIpYQXCzGab2QYzK2ukT6GZrTGzV8zs2XrtN4ZtZWY2z8wyEhWniIhES+QexBxgWEMrzawr8CvgAnfvC1wSth8LXA8UuPtJBPelvjSBcYqISISEFQh3XwZsaqTLZcDj7v5e2H9DvXVpQCczSwMygfWJilNERKKZuydu42Z5wMJwT+DAdfcB6UBfIBuY4e4PhesmAz8GtgOL3f3yRl5jPDAeIDc3d2BJSUlcsVZXV5OVlRXX2NZKOacG5Zwa4s25qKholbsXRK5094Q9gDygrIF1vwD+AXQGcoA3gC8BRwJ/BboTFJA/AGNieb2BAwd6vJYuXRr32NZKOacG5Zwa4s0ZWOkNvKemHXK5aToVwMfuvg3YZmbLgP7hunfcvRLAzB4Hvgb8LjlhioikpmRe5voEcLqZpZlZJjAYKAfeA04xs0wzM+CssF1ERJpRwvYgzGweUAjkmFkFcBvBISPcfaa7l5vZ08BaYA/wG3cvC8fOB1YDNcA/gVmJilNERKIlrEC4e3EMfe4C7opov42goIiISJLom9QiIhJJBUJERCKpQIiISCQVCBERiaQCISIikVQgREQkkgqEiIhEUoEQEXhdnDQAAAjgSURBVJFIKhAiIhJJBUJERCKpQIiISCQVCBERiaQCISIikZJ5w6CWY9YsBtx7L2RkwCefgBl07Qo7d0LHjvu3xbJ8KOOS+BqDdu6EHj1iG9e5M0yeDOPHJ/u3JSLNJKH3pG5uBQUFvnLlykMbNGsWTJiAA5aQqFquuHLOzg6KRefOsG1b0JaVBbt3Q3o6VFfv61dVFb1c17eqKihGWVn7xtVfPpxx9fvW29aOXbvIyMmBrVuDbWRn77984LgjjgjWRy3X9T1wvdmhj2vo9Q7s26ULbNkSvbx7N3To8Jn1n+7YQWZubtAeFVtDeTT0Gunp+9q6doXNm5P3oamBvp/u3ElmrB9+WvCHuJjHdejA66edRu+77/7s/9mDMLMG70mtAnHOObB4cWICEpGkSNkPfL/+9SHv5TdWIHQOYtQoIPjhpppUzFlSQ6oVh70ee6xJN6dzEGG1rbr3Xo5IsXMQ22PdDf/oo+DRBqTsJ8tkB9HMUjFnYO8H3qaSyHtSzwaGAxvc/aQG+hQC9xHcq/pjdz8zbO8K/AY4ieB3fZW7L09UrIwfz+ovfYnCwsKEvURLtKK0NPacly+Hn/0M/vnP1CiKLTwP5ZzCOTdwDuJfp51G7ya+iCSRexBzgF8AD0WtDIvAr4Bh7v6emR1db/UM4Gl3v9jMOgCZCYxTYjFkCCxYkOwoDtshFcU2Qjmnhg9LS+ndxNtM2DkId18GbGqky2XA4+7+Xth/A4CZHQGcATwQtu9y982JilNERKIl9ComM8sDFkYdYjKzukNLfYFsYIa7P2Rm+cAs4FWgP7AKmOzu2xp4jfHAeIDc3NyBJSUlccVaXV1NVlZWXGNbK+WcGpRzaog356KiogavYsLdE/YA8oCyBtb9AvgH0BnIAd4AvgQUADXA4LDfDOCOWF5v4MCBHq+lS5fGPba1Us6pQTmnhnhzBlZ6A++pybzMtYLgPMM2d/8YWEawx1ABVLj7C2G/+cCAJMUoIpKyklkgngBON7M0M8sEBgPl7v4R8L6Z1Z1vOYvgcJOIiDSjRF7mOg8oBHLMrAK4jeCcA+4+093LzexpYC2wB/iNu5eFw68D5oZXML0NjEtUnCIiEq1NTbVhZpXAu3EOzwE+bsJwWgPlnBqUc2qIN+cvuHv3qBVtqkAcDjNb6Q2dyW+jlHNqUM6pIRE5ay4mERGJpAIhIiKRVCD2mZXsAJJAOacG5ZwamjxnnYMQEZFI2oMQEZFIKhAiIhIp5QuEmQ0zs9fN7E0zm5rseJqKmc02sw1mVlavrZuZLTGzN8J/jwzbzcx+Hv4M1ppZq5zaxMw+b2ZLzazczF4xs8lhe5vN28wyzGyFmb0U5vxfYXsvM3shzPmR8EunmFnH8Pmb4fq8ZMZ/OMysvZn908wWhs/bdM5mts7MXjazNWa2MmxL6N92ShcIM2sP/BI4F+gDFJtZn+RG1WTmAMMOaJsKPOPuJwDPhM8hyP+E8DEeuL+ZYmxqNcB33f1E4BTgO+Hvsy3nvRP4urv3B/KBYWZ2CnAncG+Y8yfA1WH/q4FP3P144N6wX2s1GSiv9zwVci5y9/x633dI7N92Q7P4pcIDGAIsqvd8GjAt2XE1YX551JtNF3gdOCZcPgZ4PVz+NVAc1a81Pwjm+zo7VfImuLHWaoJ5zT4G0sL2vX/nwCJgSLicFvazZMceR649wzfErwMLCe4w2tZzXgfkHNCW0L/tlN6DAI4F3q/3vCJsa6ty3f1DgPDfurv4tbmfQ3gY4WTgBdp43uGhljXABmAJ8Baw2d1rwi7189qbc7h+C3BU80bcJO4D/pNgHjcIcmjrOTuw2MxWhffBgQT/bSfylqOtQdR9zVPxut829XMwsyzgMeAGd99q1uDt69tE3u5eC+SHt/FdAJwY1S38t9XnbGZ197pfFd7XHhrPq9XnHDrV3deHt2deYmavNdK3SXJO9T2ICuDz9Z73BNYnKZbm8G8zOwYg/HdD2N5mfg5mlk5QHOa6++Nhc5vPG8CDW/OWEpx/6WpmdR8A6+e1N+dwfRcavzVwS3QqcIGZrQNKCA4z3Ufbzhl3Xx/+u4Hgg8AgEvy3neoF4kXghPDqhw7ApcAfkxxTIv0RuDJcvpLgGH1d+7fDKx9OAbbU7ba2JhbsKjxAcF+Re+qtarN5m1n3cM8BM+sEfIPgxO1S4OKw24E51/0sLgb+6uFB6tbC3ae5e093zyP4P/tXd7+cNpyzmXU2s+y6ZWAoUEai/7aTfeIl2Q/gm8C/CI7bfj/Z8TRhXvOAD4HdBJ8mriY47voMwe1dnwG6hX2N4Gqut4CXgYJkxx9nzqcR7EavBdaEj2+25byBfsA/w5zLgB+G7V8EVgBvAr8HOobtGeHzN8P1X0x2DoeZfyHBfe/bdM5hbi+Fj1fq3qsS/betqTZERCRSqh9iEhGRBqhAiIhIJBUIERGJpAIhIiKRVCBERCSSCoRIC2BmhXWzkoq0FCoQIiISSQVC5BCY2Zjw/gtrzOzX4UR51WZ2t5mtNrNnzKx72DffzP4Rzse/oN5c/ceb2V/CezisNrPjws1nmdl8M3vNzOZaI5NIiTQHFQiRGJnZicBogknT8oFa4HKgM7Da3QcAzwK3hUMeAr7n7v0Ivs1a1z4X+KUH93D4GsE33iGYffYGgnuTfJFgziGRpEn12VxFDsVZwEDgxfDDfSeCydH2AI+EfX4HPG5mXYCu7v5s2P4g8PtwPp1j3X0BgLvvAAi3t8LdK8Lnawju5/Fc4tMSiaYCIRI7Ax5092n7NZr94IB+jc1f09hho531lmvR/09JMh1iEondM8DF4Xz8dfcD/gLB/6O6WUQvA55z9y3AJ2Z2eth+BfCsu28FKsxsRLiNjmaW2axZiMRIn1BEYuTur5rZrQR39WpHMFPud4BtQF8zW0Vwt7LR4ZArgZlhAXgbGBe2XwH82sx+FG7jkmZMQyRmms1V5DCZWbW7ZyU7DpGmpkNMIiISSXsQIiISSXsQIiISSQVCREQiqUCIiEgkFQgREYmkAiEiIpH+P31WC4562kmiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label=\"Validation-set Loss\")\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label=\"Train-set Loss\")\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.grid()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss 값이 줄어들지 않는다. .... 그러면....2019년 데이터 까지만 사용해 보자....\n",
    "#좋아 데이터 바꾸자..아... 잠깐만? 약간 변했다? 으아 민방위!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
